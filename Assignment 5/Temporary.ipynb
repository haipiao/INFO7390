{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>budget</th>\n",
       "      <th>genres</th>\n",
       "      <th>homepage</th>\n",
       "      <th>id</th>\n",
       "      <th>keywords</th>\n",
       "      <th>original_language</th>\n",
       "      <th>original_title</th>\n",
       "      <th>overview</th>\n",
       "      <th>popularity</th>\n",
       "      <th>production_companies</th>\n",
       "      <th>production_countries</th>\n",
       "      <th>release_date</th>\n",
       "      <th>revenue</th>\n",
       "      <th>runtime</th>\n",
       "      <th>spoken_languages</th>\n",
       "      <th>status</th>\n",
       "      <th>tagline</th>\n",
       "      <th>title</th>\n",
       "      <th>vote_average</th>\n",
       "      <th>vote_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>237000000</td>\n",
       "      <td>[{\"id\": 28, \"name\": \"Action\"}, {\"id\": 12, \"nam...</td>\n",
       "      <td>http://www.avatarmovie.com/</td>\n",
       "      <td>19995</td>\n",
       "      <td>[{\"id\": 1463, \"name\": \"culture clash\"}, {\"id\":...</td>\n",
       "      <td>en</td>\n",
       "      <td>Avatar</td>\n",
       "      <td>In the 22nd century, a paraplegic Marine is di...</td>\n",
       "      <td>150.437577</td>\n",
       "      <td>[{\"name\": \"Ingenious Film Partners\", \"id\": 289...</td>\n",
       "      <td>[{\"iso_3166_1\": \"US\", \"name\": \"United States o...</td>\n",
       "      <td>2009-12-10</td>\n",
       "      <td>2787965087</td>\n",
       "      <td>162.0</td>\n",
       "      <td>[{\"iso_639_1\": \"en\", \"name\": \"English\"}, {\"iso...</td>\n",
       "      <td>Released</td>\n",
       "      <td>Enter the World of Pandora.</td>\n",
       "      <td>Avatar</td>\n",
       "      <td>7.2</td>\n",
       "      <td>11800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>300000000</td>\n",
       "      <td>[{\"id\": 12, \"name\": \"Adventure\"}, {\"id\": 14, \"...</td>\n",
       "      <td>http://disney.go.com/disneypictures/pirates/</td>\n",
       "      <td>285</td>\n",
       "      <td>[{\"id\": 270, \"name\": \"ocean\"}, {\"id\": 726, \"na...</td>\n",
       "      <td>en</td>\n",
       "      <td>Pirates of the Caribbean: At World's End</td>\n",
       "      <td>Captain Barbossa, long believed to be dead, ha...</td>\n",
       "      <td>139.082615</td>\n",
       "      <td>[{\"name\": \"Walt Disney Pictures\", \"id\": 2}, {\"...</td>\n",
       "      <td>[{\"iso_3166_1\": \"US\", \"name\": \"United States o...</td>\n",
       "      <td>2007-05-19</td>\n",
       "      <td>961000000</td>\n",
       "      <td>169.0</td>\n",
       "      <td>[{\"iso_639_1\": \"en\", \"name\": \"English\"}]</td>\n",
       "      <td>Released</td>\n",
       "      <td>At the end of the world, the adventure begins.</td>\n",
       "      <td>Pirates of the Caribbean: At World's End</td>\n",
       "      <td>6.9</td>\n",
       "      <td>4500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>245000000</td>\n",
       "      <td>[{\"id\": 28, \"name\": \"Action\"}, {\"id\": 12, \"nam...</td>\n",
       "      <td>http://www.sonypictures.com/movies/spectre/</td>\n",
       "      <td>206647</td>\n",
       "      <td>[{\"id\": 470, \"name\": \"spy\"}, {\"id\": 818, \"name...</td>\n",
       "      <td>en</td>\n",
       "      <td>Spectre</td>\n",
       "      <td>A cryptic message from Bond’s past sends him o...</td>\n",
       "      <td>107.376788</td>\n",
       "      <td>[{\"name\": \"Columbia Pictures\", \"id\": 5}, {\"nam...</td>\n",
       "      <td>[{\"iso_3166_1\": \"GB\", \"name\": \"United Kingdom\"...</td>\n",
       "      <td>2015-10-26</td>\n",
       "      <td>880674609</td>\n",
       "      <td>148.0</td>\n",
       "      <td>[{\"iso_639_1\": \"fr\", \"name\": \"Fran\\u00e7ais\"},...</td>\n",
       "      <td>Released</td>\n",
       "      <td>A Plan No One Escapes</td>\n",
       "      <td>Spectre</td>\n",
       "      <td>6.3</td>\n",
       "      <td>4466</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      budget                                             genres  \\\n",
       "0  237000000  [{\"id\": 28, \"name\": \"Action\"}, {\"id\": 12, \"nam...   \n",
       "1  300000000  [{\"id\": 12, \"name\": \"Adventure\"}, {\"id\": 14, \"...   \n",
       "2  245000000  [{\"id\": 28, \"name\": \"Action\"}, {\"id\": 12, \"nam...   \n",
       "\n",
       "                                       homepage      id  \\\n",
       "0                   http://www.avatarmovie.com/   19995   \n",
       "1  http://disney.go.com/disneypictures/pirates/     285   \n",
       "2   http://www.sonypictures.com/movies/spectre/  206647   \n",
       "\n",
       "                                            keywords original_language  \\\n",
       "0  [{\"id\": 1463, \"name\": \"culture clash\"}, {\"id\":...                en   \n",
       "1  [{\"id\": 270, \"name\": \"ocean\"}, {\"id\": 726, \"na...                en   \n",
       "2  [{\"id\": 470, \"name\": \"spy\"}, {\"id\": 818, \"name...                en   \n",
       "\n",
       "                             original_title  \\\n",
       "0                                    Avatar   \n",
       "1  Pirates of the Caribbean: At World's End   \n",
       "2                                   Spectre   \n",
       "\n",
       "                                            overview  popularity  \\\n",
       "0  In the 22nd century, a paraplegic Marine is di...  150.437577   \n",
       "1  Captain Barbossa, long believed to be dead, ha...  139.082615   \n",
       "2  A cryptic message from Bond’s past sends him o...  107.376788   \n",
       "\n",
       "                                production_companies  \\\n",
       "0  [{\"name\": \"Ingenious Film Partners\", \"id\": 289...   \n",
       "1  [{\"name\": \"Walt Disney Pictures\", \"id\": 2}, {\"...   \n",
       "2  [{\"name\": \"Columbia Pictures\", \"id\": 5}, {\"nam...   \n",
       "\n",
       "                                production_countries release_date     revenue  \\\n",
       "0  [{\"iso_3166_1\": \"US\", \"name\": \"United States o...   2009-12-10  2787965087   \n",
       "1  [{\"iso_3166_1\": \"US\", \"name\": \"United States o...   2007-05-19   961000000   \n",
       "2  [{\"iso_3166_1\": \"GB\", \"name\": \"United Kingdom\"...   2015-10-26   880674609   \n",
       "\n",
       "   runtime                                   spoken_languages    status  \\\n",
       "0    162.0  [{\"iso_639_1\": \"en\", \"name\": \"English\"}, {\"iso...  Released   \n",
       "1    169.0           [{\"iso_639_1\": \"en\", \"name\": \"English\"}]  Released   \n",
       "2    148.0  [{\"iso_639_1\": \"fr\", \"name\": \"Fran\\u00e7ais\"},...  Released   \n",
       "\n",
       "                                          tagline  \\\n",
       "0                     Enter the World of Pandora.   \n",
       "1  At the end of the world, the adventure begins.   \n",
       "2                           A Plan No One Escapes   \n",
       "\n",
       "                                      title  vote_average  vote_count  \n",
       "0                                    Avatar           7.2       11800  \n",
       "1  Pirates of the Caribbean: At World's End           6.9        4500  \n",
       "2                                   Spectre           6.3        4466  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import keras\n",
    "import pandas as pd\n",
    "\n",
    "# Load the original data\n",
    "data_ori = pd.read_csv('tmdb_5000_movies.csv')\n",
    "# show data detail\n",
    "data_ori.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "budget                    int64\n",
       "genres                   object\n",
       "homepage                 object\n",
       "id                        int64\n",
       "keywords                 object\n",
       "original_language        object\n",
       "original_title           object\n",
       "overview                 object\n",
       "popularity              float64\n",
       "production_companies     object\n",
       "production_countries     object\n",
       "release_date             object\n",
       "revenue                   int64\n",
       "runtime                 float64\n",
       "spoken_languages         object\n",
       "status                   object\n",
       "tagline                  object\n",
       "title                    object\n",
       "vote_average            float64\n",
       "vote_count                int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# show columns dtypes\n",
    "data_ori.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# transfor json object to string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>budget</th>\n",
       "      <th>genres</th>\n",
       "      <th>homepage</th>\n",
       "      <th>id</th>\n",
       "      <th>keywords</th>\n",
       "      <th>original_language</th>\n",
       "      <th>original_title</th>\n",
       "      <th>overview</th>\n",
       "      <th>popularity</th>\n",
       "      <th>production_companies</th>\n",
       "      <th>production_countries</th>\n",
       "      <th>release_date</th>\n",
       "      <th>revenue</th>\n",
       "      <th>runtime</th>\n",
       "      <th>spoken_languages</th>\n",
       "      <th>status</th>\n",
       "      <th>tagline</th>\n",
       "      <th>title</th>\n",
       "      <th>vote_average</th>\n",
       "      <th>vote_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>237000000</td>\n",
       "      <td>['Action', 'Adventure', 'Fantasy', 'Science Fi...</td>\n",
       "      <td>http://www.avatarmovie.com/</td>\n",
       "      <td>19995</td>\n",
       "      <td>['culture clash', 'future', 'space war', 'spac...</td>\n",
       "      <td>en</td>\n",
       "      <td>Avatar</td>\n",
       "      <td>In the 22nd century, a paraplegic Marine is di...</td>\n",
       "      <td>150.437577</td>\n",
       "      <td>['Ingenious Film Partners', 'Twentieth Century...</td>\n",
       "      <td>['English', 'Español']</td>\n",
       "      <td>2009-12-10</td>\n",
       "      <td>2787965087</td>\n",
       "      <td>162.0</td>\n",
       "      <td>[{'iso_639_1': 'en', 'name': 'English'}, {'iso...</td>\n",
       "      <td>Released</td>\n",
       "      <td>Enter the World of Pandora.</td>\n",
       "      <td>Avatar</td>\n",
       "      <td>7.2</td>\n",
       "      <td>11800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>300000000</td>\n",
       "      <td>['Adventure', 'Fantasy', 'Action']</td>\n",
       "      <td>http://disney.go.com/disneypictures/pirates/</td>\n",
       "      <td>285</td>\n",
       "      <td>['ocean', 'drug abuse', 'exotic island', 'east...</td>\n",
       "      <td>en</td>\n",
       "      <td>Pirates of the Caribbean: At World's End</td>\n",
       "      <td>Captain Barbossa, long believed to be dead, ha...</td>\n",
       "      <td>139.082615</td>\n",
       "      <td>['Walt Disney Pictures', 'Jerry Bruckheimer Fi...</td>\n",
       "      <td>['English']</td>\n",
       "      <td>2007-05-19</td>\n",
       "      <td>961000000</td>\n",
       "      <td>169.0</td>\n",
       "      <td>[{'iso_639_1': 'en', 'name': 'English'}]</td>\n",
       "      <td>Released</td>\n",
       "      <td>At the end of the world, the adventure begins.</td>\n",
       "      <td>Pirates of the Caribbean: At World's End</td>\n",
       "      <td>6.9</td>\n",
       "      <td>4500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>245000000</td>\n",
       "      <td>['Action', 'Adventure', 'Crime']</td>\n",
       "      <td>http://www.sonypictures.com/movies/spectre/</td>\n",
       "      <td>206647</td>\n",
       "      <td>['spy', 'based on novel', 'secret agent', 'seq...</td>\n",
       "      <td>en</td>\n",
       "      <td>Spectre</td>\n",
       "      <td>A cryptic message from Bond’s past sends him o...</td>\n",
       "      <td>107.376788</td>\n",
       "      <td>['Columbia Pictures', 'Danjaq', 'B24']</td>\n",
       "      <td>['Français', 'English', 'Español', 'Italiano',...</td>\n",
       "      <td>2015-10-26</td>\n",
       "      <td>880674609</td>\n",
       "      <td>148.0</td>\n",
       "      <td>[{'iso_639_1': 'fr', 'name': 'Français'}, {'is...</td>\n",
       "      <td>Released</td>\n",
       "      <td>A Plan No One Escapes</td>\n",
       "      <td>Spectre</td>\n",
       "      <td>6.3</td>\n",
       "      <td>4466</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      budget                                             genres  \\\n",
       "0  237000000  ['Action', 'Adventure', 'Fantasy', 'Science Fi...   \n",
       "1  300000000                 ['Adventure', 'Fantasy', 'Action']   \n",
       "2  245000000                   ['Action', 'Adventure', 'Crime']   \n",
       "\n",
       "                                       homepage      id  \\\n",
       "0                   http://www.avatarmovie.com/   19995   \n",
       "1  http://disney.go.com/disneypictures/pirates/     285   \n",
       "2   http://www.sonypictures.com/movies/spectre/  206647   \n",
       "\n",
       "                                            keywords original_language  \\\n",
       "0  ['culture clash', 'future', 'space war', 'spac...                en   \n",
       "1  ['ocean', 'drug abuse', 'exotic island', 'east...                en   \n",
       "2  ['spy', 'based on novel', 'secret agent', 'seq...                en   \n",
       "\n",
       "                             original_title  \\\n",
       "0                                    Avatar   \n",
       "1  Pirates of the Caribbean: At World's End   \n",
       "2                                   Spectre   \n",
       "\n",
       "                                            overview  popularity  \\\n",
       "0  In the 22nd century, a paraplegic Marine is di...  150.437577   \n",
       "1  Captain Barbossa, long believed to be dead, ha...  139.082615   \n",
       "2  A cryptic message from Bond’s past sends him o...  107.376788   \n",
       "\n",
       "                                production_companies  \\\n",
       "0  ['Ingenious Film Partners', 'Twentieth Century...   \n",
       "1  ['Walt Disney Pictures', 'Jerry Bruckheimer Fi...   \n",
       "2             ['Columbia Pictures', 'Danjaq', 'B24']   \n",
       "\n",
       "                                production_countries release_date     revenue  \\\n",
       "0                             ['English', 'Español']   2009-12-10  2787965087   \n",
       "1                                        ['English']   2007-05-19   961000000   \n",
       "2  ['Français', 'English', 'Español', 'Italiano',...   2015-10-26   880674609   \n",
       "\n",
       "   runtime                                   spoken_languages    status  \\\n",
       "0    162.0  [{'iso_639_1': 'en', 'name': 'English'}, {'iso...  Released   \n",
       "1    169.0           [{'iso_639_1': 'en', 'name': 'English'}]  Released   \n",
       "2    148.0  [{'iso_639_1': 'fr', 'name': 'Français'}, {'is...  Released   \n",
       "\n",
       "                                          tagline  \\\n",
       "0                     Enter the World of Pandora.   \n",
       "1  At the end of the world, the adventure begins.   \n",
       "2                           A Plan No One Escapes   \n",
       "\n",
       "                                      title  vote_average  vote_count  \n",
       "0                                    Avatar           7.2       11800  \n",
       "1  Pirates of the Caribbean: At World's End           6.9        4500  \n",
       "2                                   Spectre           6.3        4466  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "movies = data_ori\n",
    "import json\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "\n",
    "# changing the genres column from json to string\n",
    "movies['genres']=movies['genres'].apply(json.loads)\n",
    "for index,i in zip(movies.index,movies['genres']):\n",
    "    list1=[]\n",
    "    for j in range(len(i)):\n",
    "        list1.append((i[j]['name']))# the key 'name' contains the name of the genre\n",
    "    movies.loc[index,'genres']=str(list1)\n",
    "    \n",
    "# changing the keywords column from json to string\n",
    "movies['keywords']=movies['keywords'].apply(json.loads)\n",
    "for index,i in zip(movies.index,movies['keywords']):\n",
    "    list1=[]\n",
    "    for j in range(len(i)):\n",
    "        list1.append((i[j]['name']))\n",
    "    movies.loc[index,'keywords']=str(list1)\n",
    "    \n",
    "## changing the production_companies column from json to string\n",
    "movies['production_companies']=movies['production_companies'].apply(json.loads)\n",
    "for index,i in zip(movies.index,movies['production_companies']):\n",
    "    list1=[]\n",
    "    for j in range(len(i)):\n",
    "        list1.append((i[j]['name']))\n",
    "    movies.loc[index,'production_companies']=str(list1)\n",
    "    \n",
    "# changing the production_countries column from json to string    \n",
    "movies['production_countries']=movies['production_countries'].apply(json.loads)\n",
    "for index,i in zip(movies.index,movies['production_countries']):\n",
    "    list1=[]\n",
    "    for j in range(len(i)):\n",
    "        list1.append((i[j]['name']))\n",
    "    movies.loc[index,'production_countries']=str(list1)\n",
    "    \n",
    "# changing the spoken_languages column from json to string    \n",
    "movies['spoken_languages']=movies['spoken_languages'].apply(json.loads)\n",
    "for index,i in zip(movies.index,movies['spoken_languages']):\n",
    "    list1=[]\n",
    "    for j in range(len(i)):\n",
    "        list1.append((i[j]['name']))\n",
    "    movies.loc[index,'production_countries']=str(list1)   \n",
    "\n",
    "data_ori.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# get feaures and labels ready"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['budget', 'genres', 'homepage', 'id', 'keywords', 'original_language',\n",
       "       'original_title', 'overview', 'popularity', 'production_companies',\n",
       "       'production_countries', 'release_date', 'revenue', 'runtime',\n",
       "       'spoken_languages', 'status', 'tagline', 'title', 'vote_average',\n",
       "       'vote_count'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# here are multiple methods, I go with my original way which is cumbersome but striaght forward\n",
    "\n",
    "data_ori.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pandas.core.indexes.base.Index"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "columns = data_ori.columns\n",
    "type(columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "columns = list(data_ori)\n",
    "type(columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['genres',\n",
       " 'id',\n",
       " 'original_language',\n",
       " 'overview',\n",
       " 'production_companies',\n",
       " 'release_date',\n",
       " 'runtime',\n",
       " 'status',\n",
       " 'title',\n",
       " 'vote_count']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# remove colmuns that is not float\n",
    "for col in columns:\n",
    "    if type(col) != float:\n",
    "        columns.remove(col)\n",
    "\n",
    "columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>budget</th>\n",
       "      <th>id</th>\n",
       "      <th>popularity</th>\n",
       "      <th>revenue</th>\n",
       "      <th>runtime</th>\n",
       "      <th>vote_average</th>\n",
       "      <th>vote_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>237000000</td>\n",
       "      <td>19995</td>\n",
       "      <td>150.437577</td>\n",
       "      <td>2787965087</td>\n",
       "      <td>162.0</td>\n",
       "      <td>7.2</td>\n",
       "      <td>11800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>300000000</td>\n",
       "      <td>285</td>\n",
       "      <td>139.082615</td>\n",
       "      <td>961000000</td>\n",
       "      <td>169.0</td>\n",
       "      <td>6.9</td>\n",
       "      <td>4500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>245000000</td>\n",
       "      <td>206647</td>\n",
       "      <td>107.376788</td>\n",
       "      <td>880674609</td>\n",
       "      <td>148.0</td>\n",
       "      <td>6.3</td>\n",
       "      <td>4466</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      budget      id  popularity     revenue  runtime  vote_average  \\\n",
       "0  237000000   19995  150.437577  2787965087    162.0           7.2   \n",
       "1  300000000     285  139.082615   961000000    169.0           6.9   \n",
       "2  245000000  206647  107.376788   880674609    148.0           6.3   \n",
       "\n",
       "   vote_count  \n",
       "0       11800  \n",
       "1        4500  \n",
       "2        4466  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# here we see some columns of type object are stil there, I don't know why. We try another method\n",
    "data=data_ori.select_dtypes(exclude='object')\n",
    "data.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# here we choose columns that we want\n",
    "features=['budget','popularity','revenue']\n",
    "label=['vote_average']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>budget</th>\n",
       "      <th>id</th>\n",
       "      <th>popularity</th>\n",
       "      <th>revenue</th>\n",
       "      <th>runtime</th>\n",
       "      <th>vote_average</th>\n",
       "      <th>vote_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>237000000.0</td>\n",
       "      <td>19995</td>\n",
       "      <td>150.437577</td>\n",
       "      <td>2.787965e+09</td>\n",
       "      <td>162.0</td>\n",
       "      <td>7.2</td>\n",
       "      <td>11800</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        budget     id  popularity       revenue  runtime  vote_average  \\\n",
       "0  237000000.0  19995  150.437577  2.787965e+09    162.0           7.2   \n",
       "\n",
       "   vote_count  \n",
       "0       11800  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# we change budget to float\n",
    "data['budget']=data['budget']+0.0\n",
    "data['revenue']=data['revenue']+0.0\n",
    "data.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>vote_average</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>4803.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>6.092172</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.194612</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>5.600000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>6.200000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>6.800000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>10.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       vote_average\n",
       "count   4803.000000\n",
       "mean       6.092172\n",
       "std        1.194612\n",
       "min        0.000000\n",
       "25%        5.600000\n",
       "50%        6.200000\n",
       "75%        6.800000\n",
       "max       10.000000"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# then we change label values according to their original value\n",
    "data[label].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>vote_average</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   vote_average\n",
       "0             3"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def change(i):\n",
    "    if i<=5.6:\n",
    "        i=0\n",
    "    if i>5.6 and i<=6.2:\n",
    "        i=1\n",
    "    if i>6.2 and i<=6.8:\n",
    "        i=2\n",
    "    if i>6.8:\n",
    "        i=3\n",
    "    return i\n",
    "data[label]=data[label].applymap(lambda x : change(x))\n",
    "data[label].head(1)        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>budget</th>\n",
       "      <th>id</th>\n",
       "      <th>popularity</th>\n",
       "      <th>revenue</th>\n",
       "      <th>runtime</th>\n",
       "      <th>vote_average</th>\n",
       "      <th>vote_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>237000000.0</td>\n",
       "      <td>19995</td>\n",
       "      <td>150.437577</td>\n",
       "      <td>2.787965e+09</td>\n",
       "      <td>162.0</td>\n",
       "      <td>3</td>\n",
       "      <td>11800</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        budget     id  popularity       revenue  runtime  vote_average  \\\n",
       "0  237000000.0  19995  150.437577  2.787965e+09    162.0             3   \n",
       "\n",
       "   vote_count  \n",
       "0       11800  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>budget</th>\n",
       "      <th>popularity</th>\n",
       "      <th>revenue</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>237000000.0</td>\n",
       "      <td>150.437577</td>\n",
       "      <td>2.787965e+09</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        budget  popularity       revenue\n",
       "0  237000000.0  150.437577  2.787965e+09"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_data = data[features]\n",
    "feature_data.head(1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>vote_average</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   vote_average\n",
       "0             3"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_data=data[label]\n",
    "label_data.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split\n",
    "trainingfeatures= feature_data[:4000]\n",
    "traininglabels=label_data[:4000]\n",
    "testingfeatures= feature_data[4000:]\n",
    "testinglabels=label_data[4000:]\n",
    "dfs = [trainingfeatures,traininglabels,testingfeatures,testinglabels]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write to csv files\n",
    "names=['trainingfeatures','traininglabels','testingfeatures','testinglabels']\n",
    "for i in range(len(dfs)):\n",
    "    df = dfs[i]\n",
    "    name= names[i]+'.csv'\n",
    "    df.to_csv(path_or_buf=name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get datasets\n",
    "x_train = pd.read_csv('trainingfeatures.csv').drop(columns=['Unnamed: 0'])\n",
    "y_train = pd.read_csv('traininglabels.csv').drop(columns=['Unnamed: 0'])\n",
    "\n",
    "temp_x=[]\n",
    "\n",
    "for row in x_train.iterrows():\n",
    "    index, data = row\n",
    "    temp_x.append(data.tolist())\n",
    "temp_y=[]\n",
    "\n",
    "for row in y_train.iterrows():\n",
    "    index, data = row\n",
    "    temp_y.append(data.tolist())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# start neuron network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-19-b96cb6bfa366>:46: softmax_cross_entropy_with_logits (from tensorflow.python.ops.nn_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "\n",
      "Future major versions of TensorFlow will allow gradients to flow\n",
      "into the labels input on backprop by default.\n",
      "\n",
      "See `tf.nn.softmax_cross_entropy_with_logits_v2`.\n",
      "\n",
      "Step 1, Minibatch Loss= 1.4028,Accuracy= 0.240\n",
      "Step 10, Minibatch Loss= 1.3863,Accuracy= 0.252\n",
      "Step 20, Minibatch Loss= 1.3863,Accuracy= 0.252\n",
      "Step 30, Minibatch Loss= 1.3863,Accuracy= 0.252\n",
      "Step 40, Minibatch Loss= 1.3863,Accuracy= 0.252\n",
      "Step 50, Minibatch Loss= 1.3863,Accuracy= 0.252\n",
      "Step 60, Minibatch Loss= 1.3863,Accuracy= 0.252\n",
      "Step 70, Minibatch Loss= 1.3863,Accuracy= 0.252\n",
      "Step 80, Minibatch Loss= 1.3863,Accuracy= 0.252\n",
      "Step 90, Minibatch Loss= 1.3863,Accuracy= 0.252\n",
      "Step 100, Minibatch Loss= 1.3863,Accuracy= 0.252\n",
      "Step 110, Minibatch Loss= 1.3863,Accuracy= 0.252\n",
      "Step 120, Minibatch Loss= 1.3863,Accuracy= 0.252\n",
      "Step 130, Minibatch Loss= 1.3863,Accuracy= 0.252\n",
      "Step 140, Minibatch Loss= 1.3863,Accuracy= 0.252\n",
      "Step 150, Minibatch Loss= 1.3863,Accuracy= 0.252\n",
      "Step 160, Minibatch Loss= 1.3863,Accuracy= 0.252\n",
      "Step 170, Minibatch Loss= 1.3863,Accuracy= 0.252\n",
      "Step 180, Minibatch Loss= 1.3863,Accuracy= 0.252\n",
      "Step 190, Minibatch Loss= 1.3863,Accuracy= 0.252\n",
      "Step 200, Minibatch Loss= 1.3863,Accuracy= 0.252\n",
      "Step 210, Minibatch Loss= 1.3863,Accuracy= 0.252\n",
      "Step 220, Minibatch Loss= 1.3863,Accuracy= 0.252\n",
      "Step 230, Minibatch Loss= 1.3863,Accuracy= 0.252\n",
      "Step 240, Minibatch Loss= 1.3863,Accuracy= 0.252\n",
      "Step 250, Minibatch Loss= 1.3863,Accuracy= 0.252\n",
      "Step 260, Minibatch Loss= 1.3863,Accuracy= 0.252\n",
      "Step 270, Minibatch Loss= 1.3863,Accuracy= 0.252\n",
      "Step 280, Minibatch Loss= 1.3863,Accuracy= 0.252\n",
      "Step 290, Minibatch Loss= 1.3863,Accuracy= 0.252\n",
      "Step 300, Minibatch Loss= 1.3863,Accuracy= 0.252\n",
      "Step 310, Minibatch Loss= 1.3863,Accuracy= 0.252\n",
      "Step 320, Minibatch Loss= 1.3863,Accuracy= 0.252\n",
      "Step 330, Minibatch Loss= 1.3863,Accuracy= 0.252\n",
      "Step 340, Minibatch Loss= 1.3863,Accuracy= 0.252\n",
      "Step 350, Minibatch Loss= 1.3863,Accuracy= 0.252\n",
      "Step 360, Minibatch Loss= 1.3863,Accuracy= 0.252\n",
      "Step 370, Minibatch Loss= 1.3863,Accuracy= 0.252\n",
      "Step 380, Minibatch Loss= 1.3863,Accuracy= 0.252\n",
      "Step 390, Minibatch Loss= 1.3863,Accuracy= 0.252\n",
      "Step 400, Minibatch Loss= 1.3863,Accuracy= 0.252\n",
      "Step 410, Minibatch Loss= 1.3863,Accuracy= 0.252\n",
      "Step 420, Minibatch Loss= 1.3863,Accuracy= 0.252\n",
      "Step 430, Minibatch Loss= 1.3863,Accuracy= 0.252\n",
      "Step 440, Minibatch Loss= 1.3863,Accuracy= 0.252\n",
      "Step 450, Minibatch Loss= 1.3863,Accuracy= 0.252\n",
      "Step 460, Minibatch Loss= 1.3863,Accuracy= 0.252\n",
      "Step 470, Minibatch Loss= 1.3863,Accuracy= 0.252\n",
      "Step 480, Minibatch Loss= 1.3863,Accuracy= 0.252\n",
      "Step 490, Minibatch Loss= 1.3863,Accuracy= 0.252\n",
      "Step 500, Minibatch Loss= 1.3863,Accuracy= 0.252\n",
      "Step 510, Minibatch Loss= 1.3863,Accuracy= 0.252\n",
      "Step 520, Minibatch Loss= 1.3863,Accuracy= 0.252\n",
      "Step 530, Minibatch Loss= 1.3863,Accuracy= 0.252\n",
      "Step 540, Minibatch Loss= 1.3863,Accuracy= 0.252\n",
      "Step 550, Minibatch Loss= 1.3863,Accuracy= 0.252\n",
      "Step 560, Minibatch Loss= 1.3863,Accuracy= 0.252\n",
      "Step 570, Minibatch Loss= 1.3863,Accuracy= 0.252\n",
      "Step 580, Minibatch Loss= 1.3863,Accuracy= 0.252\n",
      "Step 590, Minibatch Loss= 1.3863,Accuracy= 0.252\n",
      "Step 600, Minibatch Loss= 1.3863,Accuracy= 0.252\n",
      "Step 610, Minibatch Loss= 1.3863,Accuracy= 0.252\n",
      "Step 620, Minibatch Loss= 1.3863,Accuracy= 0.252\n",
      "Step 630, Minibatch Loss= 1.3863,Accuracy= 0.252\n",
      "Step 640, Minibatch Loss= 1.3863,Accuracy= 0.252\n",
      "Step 650, Minibatch Loss= 1.3863,Accuracy= 0.252\n",
      "Step 660, Minibatch Loss= 1.3863,Accuracy= 0.252\n",
      "Step 670, Minibatch Loss= 1.3863,Accuracy= 0.252\n",
      "Step 680, Minibatch Loss= 1.3863,Accuracy= 0.252\n",
      "Step 690, Minibatch Loss= 1.3863,Accuracy= 0.252\n",
      "Step 700, Minibatch Loss= 1.3863,Accuracy= 0.252\n",
      "Step 710, Minibatch Loss= 1.3863,Accuracy= 0.252\n",
      "Step 720, Minibatch Loss= 1.3863,Accuracy= 0.252\n",
      "Step 730, Minibatch Loss= 1.3863,Accuracy= 0.252\n",
      "Step 740, Minibatch Loss= 1.3863,Accuracy= 0.252\n",
      "Step 750, Minibatch Loss= 1.3863,Accuracy= 0.252\n",
      "Step 760, Minibatch Loss= 1.3863,Accuracy= 0.252\n",
      "Step 770, Minibatch Loss= 1.3863,Accuracy= 0.252\n",
      "Step 780, Minibatch Loss= 1.3863,Accuracy= 0.252\n",
      "Step 790, Minibatch Loss= 1.3863,Accuracy= 0.252\n",
      "Step 800, Minibatch Loss= 1.3863,Accuracy= 0.252\n",
      "Step 810, Minibatch Loss= 1.3863,Accuracy= 0.252\n",
      "Step 820, Minibatch Loss= 1.3863,Accuracy= 0.252\n",
      "Step 830, Minibatch Loss= 1.3863,Accuracy= 0.252\n",
      "Step 840, Minibatch Loss= 1.3863,Accuracy= 0.252\n",
      "Step 850, Minibatch Loss= 1.3863,Accuracy= 0.252\n",
      "Step 860, Minibatch Loss= 1.3863,Accuracy= 0.252\n",
      "Step 870, Minibatch Loss= 1.3863,Accuracy= 0.252\n",
      "Step 880, Minibatch Loss= 1.3863,Accuracy= 0.252\n",
      "Step 890, Minibatch Loss= 1.3863,Accuracy= 0.252\n",
      "Step 900, Minibatch Loss= 1.3863,Accuracy= 0.252\n",
      "Step 910, Minibatch Loss= 1.3863,Accuracy= 0.252\n",
      "Step 920, Minibatch Loss= 1.3863,Accuracy= 0.252\n",
      "Step 930, Minibatch Loss= 1.3863,Accuracy= 0.252\n",
      "Step 940, Minibatch Loss= 1.3863,Accuracy= 0.252\n",
      "Step 950, Minibatch Loss= 1.3863,Accuracy= 0.252\n",
      "Step 960, Minibatch Loss= 1.3863,Accuracy= 0.252\n",
      "Step 970, Minibatch Loss= 1.3863,Accuracy= 0.252\n",
      "Step 980, Minibatch Loss= 1.3863,Accuracy= 0.252\n",
      "Step 990, Minibatch Loss= 1.3863,Accuracy= 0.252\n",
      "Step 1000, Minibatch Loss= 1.3863,Accuracy= 0.252\n",
      "Step 1010, Minibatch Loss= 1.3863,Accuracy= 0.252\n",
      "Step 1020, Minibatch Loss= 1.3863,Accuracy= 0.252\n",
      "Step 1030, Minibatch Loss= 1.3863,Accuracy= 0.252\n",
      "Step 1040, Minibatch Loss= 1.3863,Accuracy= 0.252\n",
      "Step 1050, Minibatch Loss= 1.3863,Accuracy= 0.252\n",
      "Step 1060, Minibatch Loss= 1.3863,Accuracy= 0.252\n",
      "Step 1070, Minibatch Loss= 1.3863,Accuracy= 0.252\n",
      "Step 1080, Minibatch Loss= 1.3863,Accuracy= 0.252\n",
      "Step 1090, Minibatch Loss= 1.3863,Accuracy= 0.252\n",
      "Step 1100, Minibatch Loss= 1.3863,Accuracy= 0.252\n",
      "Step 1110, Minibatch Loss= 1.3863,Accuracy= 0.252\n",
      "Step 1120, Minibatch Loss= 1.3863,Accuracy= 0.252\n",
      "Step 1130, Minibatch Loss= 1.3863,Accuracy= 0.252\n",
      "Step 1140, Minibatch Loss= 1.3863,Accuracy= 0.252\n",
      "Step 1150, Minibatch Loss= 1.3863,Accuracy= 0.252\n",
      "Step 1160, Minibatch Loss= 1.3863,Accuracy= 0.252\n",
      "Step 1170, Minibatch Loss= 1.3863,Accuracy= 0.252\n",
      "Step 1180, Minibatch Loss= 1.3863,Accuracy= 0.252\n",
      "Step 1190, Minibatch Loss= 1.3863,Accuracy= 0.252\n",
      "Step 1200, Minibatch Loss= 1.3863,Accuracy= 0.252\n",
      "Step 1210, Minibatch Loss= 1.3863,Accuracy= 0.252\n",
      "Step 1220, Minibatch Loss= 1.3863,Accuracy= 0.252\n",
      "Step 1230, Minibatch Loss= 1.3863,Accuracy= 0.252\n",
      "Step 1240, Minibatch Loss= 1.3863,Accuracy= 0.252\n",
      "Step 1250, Minibatch Loss= 1.3863,Accuracy= 0.252\n",
      "Step 1260, Minibatch Loss= 1.3863,Accuracy= 0.252\n",
      "Step 1270, Minibatch Loss= 1.3863,Accuracy= 0.252\n",
      "Step 1280, Minibatch Loss= 1.3863,Accuracy= 0.252\n",
      "Step 1290, Minibatch Loss= 1.3863,Accuracy= 0.252\n",
      "Step 1300, Minibatch Loss= 1.3863,Accuracy= 0.252\n",
      "Step 1310, Minibatch Loss= 1.3863,Accuracy= 0.252\n",
      "Step 1320, Minibatch Loss= 1.3863,Accuracy= 0.252\n",
      "Step 1330, Minibatch Loss= 1.3863,Accuracy= 0.252\n",
      "Step 1340, Minibatch Loss= 1.3863,Accuracy= 0.252\n",
      "Step 1350, Minibatch Loss= 1.3863,Accuracy= 0.252\n",
      "Step 1360, Minibatch Loss= 1.3863,Accuracy= 0.252\n",
      "Step 1370, Minibatch Loss= 1.3863,Accuracy= 0.252\n",
      "Step 1380, Minibatch Loss= 1.3863,Accuracy= 0.252\n",
      "Step 1390, Minibatch Loss= 1.3863,Accuracy= 0.252\n",
      "Step 1400, Minibatch Loss= 1.3863,Accuracy= 0.252\n",
      "Step 1410, Minibatch Loss= 1.3863,Accuracy= 0.252\n",
      "Step 1420, Minibatch Loss= 1.3863,Accuracy= 0.252\n",
      "Step 1430, Minibatch Loss= 1.3863,Accuracy= 0.252\n",
      "Step 1440, Minibatch Loss= 1.3863,Accuracy= 0.252\n",
      "Step 1450, Minibatch Loss= 1.3863,Accuracy= 0.252\n",
      "Step 1460, Minibatch Loss= 1.3863,Accuracy= 0.252\n",
      "Step 1470, Minibatch Loss= 1.3863,Accuracy= 0.252\n",
      "Step 1480, Minibatch Loss= 1.3863,Accuracy= 0.252\n",
      "Step 1490, Minibatch Loss= 1.3863,Accuracy= 0.252\n",
      "Step 1500, Minibatch Loss= 1.3863,Accuracy= 0.252\n",
      "Optimization Finished!\n"
     ]
    }
   ],
   "source": [
    "# Parameters\n",
    "learning_rate = 0.3\n",
    "num_steps = 1500\n",
    "batch_size = 1000\n",
    "display_step = 10\n",
    "\n",
    "# Network Parameters\n",
    "n_hidden_1 = 100 # 1st layer number of neurons\n",
    "n_hidden_2 = 20 # 2nd layer number of neurons\n",
    "num_input =  3 # MNIST data input (img shape: 28*28)\n",
    "num_classes = 4 # MNIST total classes (0-9 digits)\n",
    "\n",
    "# tf Graph input\n",
    "X = tf.placeholder(\"float\", [None, num_input])\n",
    "Y = tf.placeholder(\"float\", [None, num_classes])\n",
    "\n",
    "# Store layers weight & bias\n",
    "weights = {\n",
    "    'h1': tf.Variable(tf.random_normal([num_input, n_hidden_1])),\n",
    "    'h2': tf.Variable(tf.random_normal([n_hidden_1, n_hidden_2])),\n",
    "    'out': tf.Variable(tf.random_normal([n_hidden_2, num_classes]))\n",
    "}\n",
    "biases = {\n",
    "    'b1': tf.Variable(tf.random_normal([n_hidden_1])),\n",
    "    'b2': tf.Variable(tf.random_normal([n_hidden_2])),\n",
    "    'out': tf.Variable(tf.random_normal([num_classes]))\n",
    "}\n",
    "\n",
    "# Create model\n",
    "def neural_net(x):\n",
    "    # Hidden fully connected layer with 256 neurons\n",
    "    layer_1 = tf.nn.softmax(tf.add(tf.matmul(x, weights['h1']), biases['b1']))\n",
    "    # Hidden fully connected layer with 256 neurons\n",
    "    layer_2 = tf.nn.relu(tf.add(tf.matmul(layer_1, weights['h2']), biases['b2']))\n",
    "    # Output fully connected layer with a neuron for each class\n",
    "    out_layer = tf.nn.tanh(tf.matmul(layer_2, weights['out']) + biases['out'])\n",
    "    return out_layer\n",
    "\n",
    "\n",
    "# Construct model\n",
    "logits = neural_net(X)\n",
    "\n",
    "\n",
    "# Define loss and optimizer\n",
    "loss_op = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(\n",
    "    logits=logits, labels=Y))\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate)\n",
    "train_op = optimizer.minimize(loss_op)\n",
    "\n",
    "\n",
    "# Evaluate model (with test logits, for dropout to be disabled)\n",
    "correct_pred = tf.equal(tf.argmax(logits, 1), tf.argmax(Y, 1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32))\n",
    "\n",
    "# Initialize the variables (i.e. assign their default value)\n",
    "init = tf.global_variables_initializer()\n",
    "    \n",
    "x = np.array(temp_x)\n",
    "\n",
    "y=np.array(keras.utils.to_categorical(y_train))\n",
    "dataset = tf.data.Dataset.from_tensor_slices((x,y))\n",
    "iter = dataset.make_one_shot_iterator()\n",
    "\n",
    "def next_batch(num, data, labels):\n",
    "    '''\n",
    "    Return a total of `num` random samples and labels. \n",
    "    '''\n",
    "    idx = np.arange(0 , len(data))\n",
    "    np.random.shuffle(idx)\n",
    "    idx = idx[:num]\n",
    "    data_shuffle = [data[ i] for i in idx]\n",
    "    labels_shuffle = [labels[ i] for i in idx]\n",
    "\n",
    "    return np.asarray(data_shuffle), np.asarray(labels_shuffle)\n",
    "\n",
    "# Start training\n",
    "with tf.Session() as sess:\n",
    "\n",
    "    # Run the initializer\n",
    "    sess.run(init)\n",
    "\n",
    "    for step in range(1, num_steps+1):\n",
    "        batch_x,batch_y=(x,y)\n",
    "        # Run optimization op (backprop)\n",
    "        sess.run(train_op, feed_dict={X: batch_x, Y: batch_y})\n",
    "        if step % display_step == 0 or step == 1:\n",
    "            # Calculate batch loss and accuracy\n",
    "            loss, acc = sess.run([loss_op, accuracy], feed_dict={X: batch_x,\n",
    "                                                                 Y: batch_y})\n",
    "            print(\"Step \" + str(step) + \", Minibatch Loss= \" + \\\n",
    "                  \"{:.4f}\".format(loss) + \",Accuracy= \" + \\\n",
    "                  \"{:.3f}\".format(acc))\n",
    "\n",
    "    print(\"Optimization Finished!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2.37000000e+08, 1.50437577e+02, 2.78796509e+09],\n",
       "       [3.00000000e+08, 1.39082615e+02, 9.61000000e+08],\n",
       "       [2.45000000e+08, 1.07376788e+02, 8.80674609e+08],\n",
       "       ...,\n",
       "       [2.60000000e+06, 2.27939290e+01, 1.19500000e+08],\n",
       "       [2.60000000e+06, 1.40134140e+01, 3.29808800e+07],\n",
       "       [2.15928000e+06, 1.32654320e+01, 1.07000000e+07]])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., 1.],\n",
       "       [0., 0., 0., 1.],\n",
       "       [0., 0., 1., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., 1.],\n",
       "       [0., 1., 0., 0.],\n",
       "       [0., 0., 0., 1.]], dtype=float32)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[2.37000000e+08, 1.50437577e+02, 2.78796509e+09],\n",
       "        [3.00000000e+08, 1.39082615e+02, 9.61000000e+08],\n",
       "        [2.45000000e+08, 1.07376788e+02, 8.80674609e+08],\n",
       "        ...,\n",
       "        [2.60000000e+06, 2.27939290e+01, 1.19500000e+08],\n",
       "        [2.60000000e+06, 1.40134140e+01, 3.29808800e+07],\n",
       "        [2.15928000e+06, 1.32654320e+01, 1.07000000e+07]]])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = np.expand_dims(x,axis=0)\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[0., 0., 0., 1.],\n",
       "        [0., 0., 0., 1.],\n",
       "        [0., 0., 1., 0.],\n",
       "        ...,\n",
       "        [0., 0., 0., 1.],\n",
       "        [0., 1., 0., 0.],\n",
       "        [0., 0., 0., 1.]]], dtype=float32)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = np.expand_dims(y,axis=0)\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Failed to create a one-shot iterator for a dataset. `Dataset.make_one_shot_iterator()` does not support datasets that capture stateful objects, such as a `Variable` or `LookupTable`. In these cases, use `Dataset.make_initializable_iterator()`. (Original error: Cannot capture a stateful node (name:IteratorGetNext, type:IteratorGetNext) by value.)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/tensorflow/python/data/ops/dataset_ops.py\u001b[0m in \u001b[0;36mmake_one_shot_iterator\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    194\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 195\u001b[0;31m       \u001b[0m_make_dataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_to_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_default_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    196\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mValueError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/function.py\u001b[0m in \u001b[0;36madd_to_graph\u001b[0;34m(self, g)\u001b[0m\n\u001b[1;32m    478\u001b[0m     \u001b[0;34m\"\"\"Adds this function into the graph g.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 479\u001b[0;31m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_create_definition_if_needed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    480\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/function.py\u001b[0m in \u001b[0;36m_create_definition_if_needed\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    334\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgraph_mode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 335\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_create_definition_if_needed_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    336\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/function.py\u001b[0m in \u001b[0;36m_create_definition_if_needed_impl\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    343\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_func\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_arg_names\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_arg_types\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_func_name\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 344\u001b[0;31m         self._capture_by_value, self._caller_device)\n\u001b[0m\u001b[1;32m    345\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/function.py\u001b[0m in \u001b[0;36mfunc_graph_from_py_func\u001b[0;34m(func, arg_names, arg_types, name, capture_by_value, device, colocation_stack, container, collections_ref, arg_shapes)\u001b[0m\n\u001b[1;32m    863\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mvs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvariable_scope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcustom_getter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfunc_graph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetvar\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 864\u001b[0;31m       \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mfunc_graph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    865\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/tensorflow/python/data/ops/dataset_ops.py\u001b[0m in \u001b[0;36m_make_dataset\u001b[0;34m()\u001b[0m\n\u001b[1;32m    191\u001b[0m         \u001b[0mdataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_ModelDataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 192\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_as_variant_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    193\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/tensorflow/python/data/ops/dataset_ops.py\u001b[0m in \u001b[0;36m_as_variant_tensor\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   2130\u001b[0m     return gen_dataset_ops.repeat_dataset(\n\u001b[0;32m-> 2131\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_input_dataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_as_variant_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2132\u001b[0m         \u001b[0mcount\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_count\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/tensorflow/python/data/ops/dataset_ops.py\u001b[0m in \u001b[0;36m_as_variant_tensor\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1582\u001b[0m         output_shapes=nest.flatten(\n\u001b[0;32m-> 1583\u001b[0;31m             sparse.as_dense_shapes(self.output_shapes, self.output_classes)))\n\u001b[0m\u001b[1;32m   1584\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/tensorflow/python/ops/gen_dataset_ops.py\u001b[0m in \u001b[0;36mtensor_slice_dataset\u001b[0;34m(components, output_shapes, name)\u001b[0m\n\u001b[1;32m   6417\u001b[0m         \u001b[0;34m\"TensorSliceDataset\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcomponents\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcomponents\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 6418\u001b[0;31m         output_shapes=output_shapes, name=name)\n\u001b[0m\u001b[1;32m   6419\u001b[0m     \u001b[0m_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_op\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py\u001b[0m in \u001b[0;36m_apply_op_helper\u001b[0;34m(self, op_type_name, name, **keywords)\u001b[0m\n\u001b[1;32m    786\u001b[0m                          \u001b[0minput_types\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_types\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattr_protos\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 787\u001b[0;31m                          op_def=op_def)\n\u001b[0m\u001b[1;32m    788\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0moutput_structure\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop_def\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_stateful\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/function.py\u001b[0m in \u001b[0;36mcreate_op\u001b[0;34m(self, op_type, inputs, data_types, **kwargs)\u001b[0m\n\u001b[1;32m    735\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mEagerTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgraph\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 736\u001b[0;31m         \u001b[0minputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcapture\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    737\u001b[0m     return super(_FuncGraph, self).create_op(op_type, inputs, data_types,\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/function.py\u001b[0m in \u001b[0;36mcapture\u001b[0;34m(self, tensor, name)\u001b[0m\n\u001b[1;32m    745\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_capture_by_value\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 746\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_add_tensor_and_parents\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    747\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/function.py\u001b[0m in \u001b[0;36m_add_tensor_and_parents\u001b[0;34m(self, tensor)\u001b[0m\n\u001b[1;32m    783\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_add_tensor_and_parents\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 784\u001b[0;31m     \u001b[0mop\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_add_op_and_parents\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mop\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    785\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalue_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/function.py\u001b[0m in \u001b[0;36m_add_op_and_parents\u001b[0;34m(self, op)\u001b[0m\n\u001b[1;32m    792\u001b[0m       raise ValueError(\"Cannot capture a stateful node (name:%s, type:%s) \"\n\u001b[0;32m--> 793\u001b[0;31m                        \"by value.\" % (op.name, op.type))\n\u001b[0m\u001b[1;32m    794\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtype\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m\"Placeholder\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"PlaceholderV2\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Cannot capture a stateful node (name:IteratorGetNext, type:IteratorGetNext) by value.",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-25-5bfe2e4baf5c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mfeatures\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mdataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_tensor_slices\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrepeat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0miter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmake_one_shot_iterator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0miter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_next\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/tensorflow/python/data/ops/dataset_ops.py\u001b[0m in \u001b[0;36mmake_one_shot_iterator\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    201\u001b[0m             \u001b[0;34m\"capture stateful objects, such as a `Variable` or `LookupTable`. \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    202\u001b[0m             \u001b[0;34m\"In these cases, use `Dataset.make_initializable_iterator()`. \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 203\u001b[0;31m             \"(Original error: %s)\" % err)\n\u001b[0m\u001b[1;32m    204\u001b[0m       \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    205\u001b[0m         \u001b[0msix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreraise\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mValueError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Failed to create a one-shot iterator for a dataset. `Dataset.make_one_shot_iterator()` does not support datasets that capture stateful objects, such as a `Variable` or `LookupTable`. In these cases, use `Dataset.make_initializable_iterator()`. (Original error: Cannot capture a stateful node (name:IteratorGetNext, type:IteratorGetNext) by value.)"
     ]
    }
   ],
   "source": [
    "EPOCHS = 10000\n",
    "BATCH_SIZE = 1000\n",
    "# using two numpy arrays\n",
    "features, labels = (x, y)\n",
    "dataset = tf.data.Dataset.from_tensor_slices((features,labels)).repeat()\n",
    "iter = dataset.make_one_shot_iterator()\n",
    "x, y = iter.get_next()\n",
    "\n",
    "# make a simple model 第一层\n",
    "net = tf.layers.dense(x, 100, activation=tf.tanh) # pass the first value \n",
    "\n",
    "#from iter.get_next() as input 第二层\n",
    "net = tf.layers.dense(net, 20, activation=tf.tanh)  # 激活函数是 tanh\n",
    "\n",
    "prediction = tf.layers.dense(net, 4, activation=tf.tanh) #output 输出层\n",
    "\n",
    "loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(\n",
    "    logits=prediction, labels=y)) \n",
    "\n",
    "#tf.losses.mean_squared_error(prediction, y) # pass the second value \n",
    "correct_pred = tf.equal(tf.argmax(prediction, 1), tf.argmax(y, 1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32))\n",
    "\n",
    "\n",
    "#from iter.get_net() as label\n",
    "train_op = tf.train.AdamOptimizer().minimize(loss)\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    sess.run(tf.local_variables_initializer())\n",
    "    for i in range(EPOCHS):\n",
    "        _, loss_value,acc_value = sess.run([train_op, loss,accuracy])\n",
    "        print(\"Iter: {}, Loss: {:.4f}\".format(i+1, loss_value)) \n",
    "       \n",
    "        print(\"Accurancy: \" +str(acc_value))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
