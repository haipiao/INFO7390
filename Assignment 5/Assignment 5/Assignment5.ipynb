{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment 5\n",
    "**_Bo Cao,  NUID:  001834167_**\n",
    "\n",
    "**_Boyang Wei, NUID:001883667_**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>budget</th>\n",
       "      <th>genres</th>\n",
       "      <th>homepage</th>\n",
       "      <th>id</th>\n",
       "      <th>keywords</th>\n",
       "      <th>original_language</th>\n",
       "      <th>original_title</th>\n",
       "      <th>overview</th>\n",
       "      <th>popularity</th>\n",
       "      <th>production_companies</th>\n",
       "      <th>production_countries</th>\n",
       "      <th>release_date</th>\n",
       "      <th>revenue</th>\n",
       "      <th>runtime</th>\n",
       "      <th>spoken_languages</th>\n",
       "      <th>status</th>\n",
       "      <th>tagline</th>\n",
       "      <th>title</th>\n",
       "      <th>vote_average</th>\n",
       "      <th>vote_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>237000000</td>\n",
       "      <td>[{\"id\": 28, \"name\": \"Action\"}, {\"id\": 12, \"nam...</td>\n",
       "      <td>http://www.avatarmovie.com/</td>\n",
       "      <td>19995</td>\n",
       "      <td>[{\"id\": 1463, \"name\": \"culture clash\"}, {\"id\":...</td>\n",
       "      <td>en</td>\n",
       "      <td>Avatar</td>\n",
       "      <td>In the 22nd century, a paraplegic Marine is di...</td>\n",
       "      <td>150.437577</td>\n",
       "      <td>[{\"name\": \"Ingenious Film Partners\", \"id\": 289...</td>\n",
       "      <td>[{\"iso_3166_1\": \"US\", \"name\": \"United States o...</td>\n",
       "      <td>2009-12-10</td>\n",
       "      <td>2787965087</td>\n",
       "      <td>162.0</td>\n",
       "      <td>[{\"iso_639_1\": \"en\", \"name\": \"English\"}, {\"iso...</td>\n",
       "      <td>Released</td>\n",
       "      <td>Enter the World of Pandora.</td>\n",
       "      <td>Avatar</td>\n",
       "      <td>7.2</td>\n",
       "      <td>11800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>300000000</td>\n",
       "      <td>[{\"id\": 12, \"name\": \"Adventure\"}, {\"id\": 14, \"...</td>\n",
       "      <td>http://disney.go.com/disneypictures/pirates/</td>\n",
       "      <td>285</td>\n",
       "      <td>[{\"id\": 270, \"name\": \"ocean\"}, {\"id\": 726, \"na...</td>\n",
       "      <td>en</td>\n",
       "      <td>Pirates of the Caribbean: At World's End</td>\n",
       "      <td>Captain Barbossa, long believed to be dead, ha...</td>\n",
       "      <td>139.082615</td>\n",
       "      <td>[{\"name\": \"Walt Disney Pictures\", \"id\": 2}, {\"...</td>\n",
       "      <td>[{\"iso_3166_1\": \"US\", \"name\": \"United States o...</td>\n",
       "      <td>2007-05-19</td>\n",
       "      <td>961000000</td>\n",
       "      <td>169.0</td>\n",
       "      <td>[{\"iso_639_1\": \"en\", \"name\": \"English\"}]</td>\n",
       "      <td>Released</td>\n",
       "      <td>At the end of the world, the adventure begins.</td>\n",
       "      <td>Pirates of the Caribbean: At World's End</td>\n",
       "      <td>6.9</td>\n",
       "      <td>4500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>245000000</td>\n",
       "      <td>[{\"id\": 28, \"name\": \"Action\"}, {\"id\": 12, \"nam...</td>\n",
       "      <td>http://www.sonypictures.com/movies/spectre/</td>\n",
       "      <td>206647</td>\n",
       "      <td>[{\"id\": 470, \"name\": \"spy\"}, {\"id\": 818, \"name...</td>\n",
       "      <td>en</td>\n",
       "      <td>Spectre</td>\n",
       "      <td>A cryptic message from Bond’s past sends him o...</td>\n",
       "      <td>107.376788</td>\n",
       "      <td>[{\"name\": \"Columbia Pictures\", \"id\": 5}, {\"nam...</td>\n",
       "      <td>[{\"iso_3166_1\": \"GB\", \"name\": \"United Kingdom\"...</td>\n",
       "      <td>2015-10-26</td>\n",
       "      <td>880674609</td>\n",
       "      <td>148.0</td>\n",
       "      <td>[{\"iso_639_1\": \"fr\", \"name\": \"Fran\\u00e7ais\"},...</td>\n",
       "      <td>Released</td>\n",
       "      <td>A Plan No One Escapes</td>\n",
       "      <td>Spectre</td>\n",
       "      <td>6.3</td>\n",
       "      <td>4466</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      budget                                             genres  \\\n",
       "0  237000000  [{\"id\": 28, \"name\": \"Action\"}, {\"id\": 12, \"nam...   \n",
       "1  300000000  [{\"id\": 12, \"name\": \"Adventure\"}, {\"id\": 14, \"...   \n",
       "2  245000000  [{\"id\": 28, \"name\": \"Action\"}, {\"id\": 12, \"nam...   \n",
       "\n",
       "                                       homepage      id  \\\n",
       "0                   http://www.avatarmovie.com/   19995   \n",
       "1  http://disney.go.com/disneypictures/pirates/     285   \n",
       "2   http://www.sonypictures.com/movies/spectre/  206647   \n",
       "\n",
       "                                            keywords original_language  \\\n",
       "0  [{\"id\": 1463, \"name\": \"culture clash\"}, {\"id\":...                en   \n",
       "1  [{\"id\": 270, \"name\": \"ocean\"}, {\"id\": 726, \"na...                en   \n",
       "2  [{\"id\": 470, \"name\": \"spy\"}, {\"id\": 818, \"name...                en   \n",
       "\n",
       "                             original_title  \\\n",
       "0                                    Avatar   \n",
       "1  Pirates of the Caribbean: At World's End   \n",
       "2                                   Spectre   \n",
       "\n",
       "                                            overview  popularity  \\\n",
       "0  In the 22nd century, a paraplegic Marine is di...  150.437577   \n",
       "1  Captain Barbossa, long believed to be dead, ha...  139.082615   \n",
       "2  A cryptic message from Bond’s past sends him o...  107.376788   \n",
       "\n",
       "                                production_companies  \\\n",
       "0  [{\"name\": \"Ingenious Film Partners\", \"id\": 289...   \n",
       "1  [{\"name\": \"Walt Disney Pictures\", \"id\": 2}, {\"...   \n",
       "2  [{\"name\": \"Columbia Pictures\", \"id\": 5}, {\"nam...   \n",
       "\n",
       "                                production_countries release_date     revenue  \\\n",
       "0  [{\"iso_3166_1\": \"US\", \"name\": \"United States o...   2009-12-10  2787965087   \n",
       "1  [{\"iso_3166_1\": \"US\", \"name\": \"United States o...   2007-05-19   961000000   \n",
       "2  [{\"iso_3166_1\": \"GB\", \"name\": \"United Kingdom\"...   2015-10-26   880674609   \n",
       "\n",
       "   runtime                                   spoken_languages    status  \\\n",
       "0    162.0  [{\"iso_639_1\": \"en\", \"name\": \"English\"}, {\"iso...  Released   \n",
       "1    169.0           [{\"iso_639_1\": \"en\", \"name\": \"English\"}]  Released   \n",
       "2    148.0  [{\"iso_639_1\": \"fr\", \"name\": \"Fran\\u00e7ais\"},...  Released   \n",
       "\n",
       "                                          tagline  \\\n",
       "0                     Enter the World of Pandora.   \n",
       "1  At the end of the world, the adventure begins.   \n",
       "2                           A Plan No One Escapes   \n",
       "\n",
       "                                      title  vote_average  vote_count  \n",
       "0                                    Avatar           7.2       11800  \n",
       "1  Pirates of the Caribbean: At World's End           6.9        4500  \n",
       "2                                   Spectre           6.3        4466  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import keras\n",
    "import pandas as pd\n",
    "\n",
    "# Load the original data\n",
    "data_ori = pd.read_csv('tmdb_5000_movies.csv')\n",
    "# show data detail\n",
    "data_ori.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "budget                    int64\n",
       "genres                   object\n",
       "homepage                 object\n",
       "id                        int64\n",
       "keywords                 object\n",
       "original_language        object\n",
       "original_title           object\n",
       "overview                 object\n",
       "popularity              float64\n",
       "production_companies     object\n",
       "production_countries     object\n",
       "release_date             object\n",
       "revenue                   int64\n",
       "runtime                 float64\n",
       "spoken_languages         object\n",
       "status                   object\n",
       "tagline                  object\n",
       "title                    object\n",
       "vote_average            float64\n",
       "vote_count                int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# show columns dtypes\n",
    "data_ori.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transfor json object to string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>budget</th>\n",
       "      <th>genres</th>\n",
       "      <th>homepage</th>\n",
       "      <th>id</th>\n",
       "      <th>keywords</th>\n",
       "      <th>original_language</th>\n",
       "      <th>original_title</th>\n",
       "      <th>overview</th>\n",
       "      <th>popularity</th>\n",
       "      <th>production_companies</th>\n",
       "      <th>production_countries</th>\n",
       "      <th>release_date</th>\n",
       "      <th>revenue</th>\n",
       "      <th>runtime</th>\n",
       "      <th>spoken_languages</th>\n",
       "      <th>status</th>\n",
       "      <th>tagline</th>\n",
       "      <th>title</th>\n",
       "      <th>vote_average</th>\n",
       "      <th>vote_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>237000000</td>\n",
       "      <td>['Action', 'Adventure', 'Fantasy', 'Science Fi...</td>\n",
       "      <td>http://www.avatarmovie.com/</td>\n",
       "      <td>19995</td>\n",
       "      <td>['culture clash', 'future', 'space war', 'spac...</td>\n",
       "      <td>en</td>\n",
       "      <td>Avatar</td>\n",
       "      <td>In the 22nd century, a paraplegic Marine is di...</td>\n",
       "      <td>150.437577</td>\n",
       "      <td>['Ingenious Film Partners', 'Twentieth Century...</td>\n",
       "      <td>['English', 'Español']</td>\n",
       "      <td>2009-12-10</td>\n",
       "      <td>2787965087</td>\n",
       "      <td>162.0</td>\n",
       "      <td>[{'iso_639_1': 'en', 'name': 'English'}, {'iso...</td>\n",
       "      <td>Released</td>\n",
       "      <td>Enter the World of Pandora.</td>\n",
       "      <td>Avatar</td>\n",
       "      <td>7.2</td>\n",
       "      <td>11800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>300000000</td>\n",
       "      <td>['Adventure', 'Fantasy', 'Action']</td>\n",
       "      <td>http://disney.go.com/disneypictures/pirates/</td>\n",
       "      <td>285</td>\n",
       "      <td>['ocean', 'drug abuse', 'exotic island', 'east...</td>\n",
       "      <td>en</td>\n",
       "      <td>Pirates of the Caribbean: At World's End</td>\n",
       "      <td>Captain Barbossa, long believed to be dead, ha...</td>\n",
       "      <td>139.082615</td>\n",
       "      <td>['Walt Disney Pictures', 'Jerry Bruckheimer Fi...</td>\n",
       "      <td>['English']</td>\n",
       "      <td>2007-05-19</td>\n",
       "      <td>961000000</td>\n",
       "      <td>169.0</td>\n",
       "      <td>[{'iso_639_1': 'en', 'name': 'English'}]</td>\n",
       "      <td>Released</td>\n",
       "      <td>At the end of the world, the adventure begins.</td>\n",
       "      <td>Pirates of the Caribbean: At World's End</td>\n",
       "      <td>6.9</td>\n",
       "      <td>4500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>245000000</td>\n",
       "      <td>['Action', 'Adventure', 'Crime']</td>\n",
       "      <td>http://www.sonypictures.com/movies/spectre/</td>\n",
       "      <td>206647</td>\n",
       "      <td>['spy', 'based on novel', 'secret agent', 'seq...</td>\n",
       "      <td>en</td>\n",
       "      <td>Spectre</td>\n",
       "      <td>A cryptic message from Bond’s past sends him o...</td>\n",
       "      <td>107.376788</td>\n",
       "      <td>['Columbia Pictures', 'Danjaq', 'B24']</td>\n",
       "      <td>['Français', 'English', 'Español', 'Italiano',...</td>\n",
       "      <td>2015-10-26</td>\n",
       "      <td>880674609</td>\n",
       "      <td>148.0</td>\n",
       "      <td>[{'iso_639_1': 'fr', 'name': 'Français'}, {'is...</td>\n",
       "      <td>Released</td>\n",
       "      <td>A Plan No One Escapes</td>\n",
       "      <td>Spectre</td>\n",
       "      <td>6.3</td>\n",
       "      <td>4466</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      budget                                             genres  \\\n",
       "0  237000000  ['Action', 'Adventure', 'Fantasy', 'Science Fi...   \n",
       "1  300000000                 ['Adventure', 'Fantasy', 'Action']   \n",
       "2  245000000                   ['Action', 'Adventure', 'Crime']   \n",
       "\n",
       "                                       homepage      id  \\\n",
       "0                   http://www.avatarmovie.com/   19995   \n",
       "1  http://disney.go.com/disneypictures/pirates/     285   \n",
       "2   http://www.sonypictures.com/movies/spectre/  206647   \n",
       "\n",
       "                                            keywords original_language  \\\n",
       "0  ['culture clash', 'future', 'space war', 'spac...                en   \n",
       "1  ['ocean', 'drug abuse', 'exotic island', 'east...                en   \n",
       "2  ['spy', 'based on novel', 'secret agent', 'seq...                en   \n",
       "\n",
       "                             original_title  \\\n",
       "0                                    Avatar   \n",
       "1  Pirates of the Caribbean: At World's End   \n",
       "2                                   Spectre   \n",
       "\n",
       "                                            overview  popularity  \\\n",
       "0  In the 22nd century, a paraplegic Marine is di...  150.437577   \n",
       "1  Captain Barbossa, long believed to be dead, ha...  139.082615   \n",
       "2  A cryptic message from Bond’s past sends him o...  107.376788   \n",
       "\n",
       "                                production_companies  \\\n",
       "0  ['Ingenious Film Partners', 'Twentieth Century...   \n",
       "1  ['Walt Disney Pictures', 'Jerry Bruckheimer Fi...   \n",
       "2             ['Columbia Pictures', 'Danjaq', 'B24']   \n",
       "\n",
       "                                production_countries release_date     revenue  \\\n",
       "0                             ['English', 'Español']   2009-12-10  2787965087   \n",
       "1                                        ['English']   2007-05-19   961000000   \n",
       "2  ['Français', 'English', 'Español', 'Italiano',...   2015-10-26   880674609   \n",
       "\n",
       "   runtime                                   spoken_languages    status  \\\n",
       "0    162.0  [{'iso_639_1': 'en', 'name': 'English'}, {'iso...  Released   \n",
       "1    169.0           [{'iso_639_1': 'en', 'name': 'English'}]  Released   \n",
       "2    148.0  [{'iso_639_1': 'fr', 'name': 'Français'}, {'is...  Released   \n",
       "\n",
       "                                          tagline  \\\n",
       "0                     Enter the World of Pandora.   \n",
       "1  At the end of the world, the adventure begins.   \n",
       "2                           A Plan No One Escapes   \n",
       "\n",
       "                                      title  vote_average  vote_count  \n",
       "0                                    Avatar           7.2       11800  \n",
       "1  Pirates of the Caribbean: At World's End           6.9        4500  \n",
       "2                                   Spectre           6.3        4466  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "movies = data_ori\n",
    "import json\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "\n",
    "# changing the genres column from json to string\n",
    "movies['genres']=movies['genres'].apply(json.loads)\n",
    "for index,i in zip(movies.index,movies['genres']):\n",
    "    list1=[]\n",
    "    for j in range(len(i)):\n",
    "        list1.append((i[j]['name']))# the key 'name' contains the name of the genre\n",
    "    movies.loc[index,'genres']=str(list1)\n",
    "    \n",
    "# changing the keywords column from json to string\n",
    "movies['keywords']=movies['keywords'].apply(json.loads)\n",
    "for index,i in zip(movies.index,movies['keywords']):\n",
    "    list1=[]\n",
    "    for j in range(len(i)):\n",
    "        list1.append((i[j]['name']))\n",
    "    movies.loc[index,'keywords']=str(list1)\n",
    "    \n",
    "## changing the production_companies column from json to string\n",
    "movies['production_companies']=movies['production_companies'].apply(json.loads)\n",
    "for index,i in zip(movies.index,movies['production_companies']):\n",
    "    list1=[]\n",
    "    for j in range(len(i)):\n",
    "        list1.append((i[j]['name']))\n",
    "    movies.loc[index,'production_companies']=str(list1)\n",
    "    \n",
    "# changing the production_countries column from json to string    \n",
    "movies['production_countries']=movies['production_countries'].apply(json.loads)\n",
    "for index,i in zip(movies.index,movies['production_countries']):\n",
    "    list1=[]\n",
    "    for j in range(len(i)):\n",
    "        list1.append((i[j]['name']))\n",
    "    movies.loc[index,'production_countries']=str(list1)\n",
    "    \n",
    "# changing the spoken_languages column from json to string    \n",
    "movies['spoken_languages']=movies['spoken_languages'].apply(json.loads)\n",
    "for index,i in zip(movies.index,movies['spoken_languages']):\n",
    "    list1=[]\n",
    "    for j in range(len(i)):\n",
    "        list1.append((i[j]['name']))\n",
    "    movies.loc[index,'production_countries']=str(list1)   \n",
    "\n",
    "data_ori.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get feaures and labels ready"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['budget', 'genres', 'homepage', 'id', 'keywords', 'original_language',\n",
       "       'original_title', 'overview', 'popularity', 'production_companies',\n",
       "       'production_countries', 'release_date', 'revenue', 'runtime',\n",
       "       'spoken_languages', 'status', 'tagline', 'title', 'vote_average',\n",
       "       'vote_count'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# here are multiple methods, I go with my original way which is cumbersome but striaght forward\n",
    "\n",
    "data_ori.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pandas.core.indexes.base.Index"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "columns = data_ori.columns\n",
    "type(columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "columns = list(data_ori)\n",
    "type(columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['genres',\n",
       " 'id',\n",
       " 'original_language',\n",
       " 'overview',\n",
       " 'production_companies',\n",
       " 'release_date',\n",
       " 'runtime',\n",
       " 'status',\n",
       " 'title',\n",
       " 'vote_count']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# remove colmuns that is not float\n",
    "for col in columns:\n",
    "    if type(col) != float:\n",
    "        columns.remove(col)\n",
    "\n",
    "columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>budget</th>\n",
       "      <th>id</th>\n",
       "      <th>popularity</th>\n",
       "      <th>revenue</th>\n",
       "      <th>runtime</th>\n",
       "      <th>vote_average</th>\n",
       "      <th>vote_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>237000000</td>\n",
       "      <td>19995</td>\n",
       "      <td>150.437577</td>\n",
       "      <td>2787965087</td>\n",
       "      <td>162.0</td>\n",
       "      <td>7.2</td>\n",
       "      <td>11800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>300000000</td>\n",
       "      <td>285</td>\n",
       "      <td>139.082615</td>\n",
       "      <td>961000000</td>\n",
       "      <td>169.0</td>\n",
       "      <td>6.9</td>\n",
       "      <td>4500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>245000000</td>\n",
       "      <td>206647</td>\n",
       "      <td>107.376788</td>\n",
       "      <td>880674609</td>\n",
       "      <td>148.0</td>\n",
       "      <td>6.3</td>\n",
       "      <td>4466</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      budget      id  popularity     revenue  runtime  vote_average  \\\n",
       "0  237000000   19995  150.437577  2787965087    162.0           7.2   \n",
       "1  300000000     285  139.082615   961000000    169.0           6.9   \n",
       "2  245000000  206647  107.376788   880674609    148.0           6.3   \n",
       "\n",
       "   vote_count  \n",
       "0       11800  \n",
       "1        4500  \n",
       "2        4466  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# here we see some columns of type object are stil there, I don't know why. We try another method\n",
    "data=data_ori.select_dtypes(exclude='object')\n",
    "data.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# here we choose columns that we want\n",
    "features=['popularity','revenue','vote_average']\n",
    "label=['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>budget</th>\n",
       "      <th>id</th>\n",
       "      <th>popularity</th>\n",
       "      <th>revenue</th>\n",
       "      <th>runtime</th>\n",
       "      <th>vote_average</th>\n",
       "      <th>vote_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>237000000.0</td>\n",
       "      <td>19995</td>\n",
       "      <td>150.437577</td>\n",
       "      <td>2.787965e+09</td>\n",
       "      <td>162.0</td>\n",
       "      <td>7.2</td>\n",
       "      <td>11800</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        budget     id  popularity       revenue  runtime  vote_average  \\\n",
       "0  237000000.0  19995  150.437577  2.787965e+09    162.0           7.2   \n",
       "\n",
       "   vote_count  \n",
       "0       11800  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# we change budget to float\n",
    "data['budget']=data['budget']+0.0\n",
    "data['revenue']=data['revenue']+0.0\n",
    "data.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   label\n",
       "0    3.0"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# then we change label values according to their original value\n",
    "def change(i):\n",
    "    if i<=5.6:\n",
    "        i=0.0\n",
    "    if i>5.6 and i<=6.2:\n",
    "        i=1.0\n",
    "    if i>6.2 and i<=6.8:\n",
    "        i=2.0\n",
    "    if i>6.8:\n",
    "        i=3.0\n",
    "    return i\n",
    "data[label]=data[['vote_average']].applymap(lambda x : change(x))\n",
    "data[label].head(1)        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>4803.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>1.459713</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.125132</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>3.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             label\n",
       "count  4803.000000\n",
       "mean      1.459713\n",
       "std       1.125132\n",
       "min       0.000000\n",
       "25%       0.000000\n",
       "50%       1.000000\n",
       "75%       2.000000\n",
       "max       3.000000"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[label].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>budget</th>\n",
       "      <th>id</th>\n",
       "      <th>popularity</th>\n",
       "      <th>revenue</th>\n",
       "      <th>runtime</th>\n",
       "      <th>vote_average</th>\n",
       "      <th>vote_count</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>237000000.0</td>\n",
       "      <td>19995</td>\n",
       "      <td>150.437577</td>\n",
       "      <td>2.787965e+09</td>\n",
       "      <td>162.0</td>\n",
       "      <td>7.2</td>\n",
       "      <td>11800</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        budget     id  popularity       revenue  runtime  vote_average  \\\n",
       "0  237000000.0  19995  150.437577  2.787965e+09    162.0           7.2   \n",
       "\n",
       "   vote_count  label  \n",
       "0       11800    3.0  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>popularity</th>\n",
       "      <th>revenue</th>\n",
       "      <th>vote_average</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>150.437577</td>\n",
       "      <td>2.787965e+09</td>\n",
       "      <td>7.2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   popularity       revenue  vote_average\n",
       "0  150.437577  2.787965e+09           7.2"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_data = data[features]\n",
    "feature_data.head(1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   label\n",
       "0    3.0"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_data=data[label]\n",
    "label_data.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split\n",
    "trainingfeatures= feature_data[:4000]\n",
    "traininglabels=label_data[:4000]\n",
    "testingfeatures= feature_data[4000:]\n",
    "testinglabels=label_data[4000:]\n",
    "dfs = [trainingfeatures,traininglabels,testingfeatures,testinglabels]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write to csv files\n",
    "names=['trainingfeatures','traininglabels','testingfeatures','testinglabels']\n",
    "for i in range(len(dfs)):\n",
    "    df = dfs[i]\n",
    "    name= names[i]+'.csv'\n",
    "    df.to_csv(path_or_buf=name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get datasets\n",
    "x_train = pd.read_csv('trainingfeatures.csv').drop(columns=['Unnamed: 0'])\n",
    "y_train = pd.read_csv('traininglabels.csv').drop(columns=['Unnamed: 0'])\n",
    "x_test = pd.read_csv('testingfeatures.csv').drop(columns=['Unnamed: 0'])\n",
    "y_test = pd.read_csv('testinglabels.csv').drop(columns=['Unnamed: 0'])\n",
    "temp_x_train=[]\n",
    "\n",
    "for row in x_train.iterrows():\n",
    "    index, data = row\n",
    "    temp_x_train.append(data.tolist())\n",
    "temp_y_train=[]\n",
    "\n",
    "for row in y_train.iterrows():\n",
    "    index, data = row\n",
    "    temp_y_train.append(data.tolist())\n",
    "\n",
    "temp_x_test=[]\n",
    "\n",
    "for row in x_test.iterrows():\n",
    "    index, data = row\n",
    "    temp_x_test.append(data.tolist())\n",
    "temp_y_test=[]\n",
    "\n",
    "for row in y_test.iterrows():\n",
    "    index, data = row\n",
    "    temp_y_test.append(data.tolist())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part A - Deep Learning model\n",
    "### Start neuron network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-19-572e2d91cdc5>:49: softmax_cross_entropy_with_logits (from tensorflow.python.ops.nn_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "\n",
      "Future major versions of TensorFlow will allow gradients to flow\n",
      "into the labels input on backprop by default.\n",
      "\n",
      "See `tf.nn.softmax_cross_entropy_with_logits_v2`.\n",
      "\n",
      "Step 1, Minibatch Loss= 22.4260,Accuracy= 0.258\n",
      "Step 500, Minibatch Loss= 1.3655,Accuracy= 0.296\n",
      "Step 1000, Minibatch Loss= 1.3595,Accuracy= 0.296\n",
      "Step 1500, Minibatch Loss= 1.3558,Accuracy= 0.296\n",
      "Step 2000, Minibatch Loss= 1.3321,Accuracy= 0.297\n",
      "Optimization Finished!\n",
      "Test ccuracy: 0.40971357\n"
     ]
    }
   ],
   "source": [
    "# Parameters\n",
    "learning_rate = 0.05\n",
    "num_steps = 2000\n",
    "batch_size = 1000\n",
    "display_step = 500\n",
    "\n",
    "# Network Parameters\n",
    "n_hidden_1 = 100 # 1st layer number of neurons\n",
    "n_hidden_2 = 50 # 2nd layer number of neurons\n",
    "n_hidden_3 = 20 # 3rd layer number of neurons\n",
    "num_input =  3 # MNIST data input \n",
    "num_classes = 4 # MNIST total classes (0-3 digits)\n",
    "\n",
    "# tf Graph input\n",
    "X = tf.placeholder(\"float\", [None, num_input])\n",
    "Y = tf.placeholder(\"float\", [None, num_classes])\n",
    "\n",
    "# Store layers weight & bias\n",
    "weights = {\n",
    "    'h1': tf.Variable(tf.random_normal([num_input, n_hidden_1])),\n",
    "    'h2': tf.Variable(tf.random_normal([n_hidden_1, n_hidden_2])),\n",
    "    'h3': tf.Variable(tf.random_normal([n_hidden_2,n_hidden_3])),\n",
    "    'out': tf.Variable(tf.random_normal([n_hidden_3, num_classes]))\n",
    "}\n",
    "biases = {\n",
    "    'b1': tf.Variable(tf.random_normal([n_hidden_1])),\n",
    "    'b2': tf.Variable(tf.random_normal([n_hidden_2])),\n",
    "    'b3': tf.Variable(tf.random_normal([n_hidden_3])),\n",
    "    'out': tf.Variable(tf.random_normal([num_classes]))\n",
    "}\n",
    "\n",
    "# Create model\n",
    "def neural_net(x):\n",
    "    # Hidden_1 fully connected layer \n",
    "    layer_1 = tf.nn.softmax(tf.add(tf.matmul(x, weights['h1']), biases['b1']))\n",
    "    # Hidden_2 fully connected layer \n",
    "    layer_2 = tf.nn.relu(tf.add(tf.matmul(layer_1, weights['h2']), biases['b2']))\n",
    "    #Hidden_3 fully connected layer  \n",
    "    layer_3 = tf.nn.relu(tf.add(tf.matmul(layer_2, weights['h3']), biases['b3']))\n",
    "    # Output fully connected layer with a neuron for each class\n",
    "    out_layer = tf.matmul(layer_3, weights['out']) + biases['out']\n",
    "    return out_layer\n",
    "\n",
    "# Construct model\n",
    "logits = neural_net(X)\n",
    "\n",
    "# Define loss and optimizer\n",
    "loss_op = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(\n",
    "    logits=logits, labels=Y))\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate=learning_rate)\n",
    "train_op = optimizer.minimize(loss_op)\n",
    "\n",
    "# Evaluate model (with test logits, for dropout to be disabled)\n",
    "correct_pred = tf.equal(tf.argmax(logits, 1), tf.argmax(Y, 1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32))\n",
    "\n",
    "# Initialize the variables (i.e. assign their default value)\n",
    "init = tf.global_variables_initializer()\n",
    "    \n",
    "x= np.array(temp_x_train)\n",
    "\n",
    "y=np.array(keras.utils.to_categorical(y_train))\n",
    "dataset = tf.data.Dataset.from_tensor_slices((x,y))\n",
    "iter = dataset.make_one_shot_iterator()\n",
    "\n",
    "def next_batch(num, data, labels):\n",
    "    '''\n",
    "    Return a total of `num` random samples and labels. \n",
    "    '''\n",
    "    idx = np.arange(0 , len(data))\n",
    "    np.random.shuffle(idx)\n",
    "    idx = idx[:num]\n",
    "    data_shuffle = [data[ i] for i in idx]\n",
    "    labels_shuffle = [labels[ i] for i in idx]\n",
    "\n",
    "    return np.asarray(data_shuffle), np.asarray(labels_shuffle)\n",
    "\n",
    "# Start training\n",
    "with tf.Session() as sess:\n",
    "\n",
    "    # Run the initializer\n",
    "    sess.run(init)\n",
    "\n",
    "    for step in range(1, num_steps+1):\n",
    "        batch_x,batch_y=(x,y)\n",
    "        # Run optimization op (backprop)\n",
    "        sess.run(train_op, feed_dict={X: batch_x, Y: batch_y})\n",
    "        if step % display_step == 0 or step == 1:\n",
    "            # Calculate batch loss and accuracy\n",
    "            loss, acc = sess.run([loss_op, accuracy], feed_dict={X: batch_x,\n",
    "                                                                 Y: batch_y})\n",
    "            print(\"Step \" + str(step) + \", Minibatch Loss= \" + \\\n",
    "                  \"{:.4f}\".format(loss) + \",Accuracy= \" + \\\n",
    "                  \"{:.3f}\".format(acc))\n",
    "\n",
    "    print(\"Optimization Finished!\")\n",
    "    pred = logits  # Apply softmax to logits\n",
    "    correct_prediction = tf.equal(tf.argmax(pred, 1), tf.argmax(Y, 1))\n",
    "    # Calculate accuracy\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct_prediction, \"float\"))\n",
    "    print(\"Test ccuracy:\", accuracy.eval({X: np.array(temp_x_test), Y: np.array(keras.utils.to_categorical(y_test))}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4000, 3)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., 1.],\n",
       "       [0., 0., 0., 1.],\n",
       "       [0., 0., 1., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., 1.],\n",
       "       [0., 1., 0., 0.],\n",
       "       [0., 0., 0., 1.]], dtype=float32)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model:\n",
    "Activation = tanh + relu + softmax\n",
    "\n",
    "Loss = cross_entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter: 1, Loss: 1.3924\n",
      "Accurancy: 0.235\n",
      "Iter: 501, Loss: 1.2769\n",
      "Accurancy: 0.347\n",
      "Iter: 1001, Loss: 1.2454\n",
      "Accurancy: 0.35275\n",
      "Iter: 1501, Loss: 1.2338\n",
      "Accurancy: 0.35125\n",
      "Iter: 2001, Loss: 1.2265\n",
      "Accurancy: 0.35125\n",
      "Iter: 2501, Loss: 1.2225\n",
      "Accurancy: 0.35125\n",
      "Iter: 3001, Loss: 1.2211\n",
      "Accurancy: 0.34975\n",
      "Iter: 3501, Loss: 1.2195\n",
      "Accurancy: 0.34975\n",
      "Iter: 4001, Loss: 1.2184\n",
      "Accurancy: 0.34975\n",
      "Iter: 4501, Loss: 1.1525\n",
      "Accurancy: 0.40175\n",
      "Iter: 5001, Loss: 1.1353\n",
      "Accurancy: 0.40175\n",
      "Iter: 5501, Loss: 1.1298\n",
      "Accurancy: 0.40175\n",
      "Iter: 6001, Loss: 1.1271\n",
      "Accurancy: 0.40175\n",
      "Iter: 6501, Loss: 1.1255\n",
      "Accurancy: 0.40175\n",
      "Iter: 7001, Loss: 1.1240\n",
      "Accurancy: 0.402\n",
      "Iter: 7501, Loss: 1.1231\n",
      "Accurancy: 0.40225\n",
      "Iter: 8001, Loss: 1.1226\n",
      "Accurancy: 0.40225\n",
      "Iter: 8501, Loss: 1.1223\n",
      "Accurancy: 0.40225\n",
      "Iter: 9001, Loss: 1.1220\n",
      "Accurancy: 0.40225\n",
      "Iter: 9501, Loss: 1.1218\n",
      "Accurancy: 0.40225\n",
      "Test accuracy: 0.6351183\n"
     ]
    }
   ],
   "source": [
    "EPOCHS = 10000\n",
    "BATCH_SIZE = 1000\n",
    "display_step = 500\n",
    "X = tf.placeholder(\"float\", [None, num_input])\n",
    "Y = tf.placeholder(\"float\", [None, num_classes])\n",
    "\n",
    "# using two numpy arrays\n",
    "features, labels = (X, Y)\n",
    "\n",
    "# make a simple model\n",
    "def Neuron(x):\n",
    "    net = tf.layers.dense(x, 100, activation=tf.tanh) # pass the first value \n",
    "    #from iter.get_next() as input\n",
    "    net = tf.layers.dense(net, 50, activation=tf.nn.relu)\n",
    "    net = tf.layers.dense(net, 20, activation=tf.nn.softmax)\n",
    "    prediction = tf.layers.dense(net, 4)\n",
    "    return prediction\n",
    "\n",
    "\n",
    "prediction = Neuron(X)\n",
    "loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=prediction, labels=Y)) \n",
    "\n",
    "#tf.losses.mean_squared_error(prediction, y) # pass the second value \n",
    "correct_pred = tf.equal(tf.argmax(prediction, 1), tf.argmax(Y, 1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32))\n",
    "\n",
    "#from iter.get_net() as label\n",
    "train_op = tf.train.AdamOptimizer().minimize(loss)\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    sess.run(tf.local_variables_initializer())\n",
    "    for i in range(EPOCHS):\n",
    "        _, loss_value,acc_value = sess.run([train_op, loss,accuracy],feed_dict={X: x, Y: y})\n",
    "        if i% display_step == 0:\n",
    "            print(\"Iter: {}, Loss: {:.4f}\".format(i+1, loss_value)) \n",
    "            print(\"Accurancy: \" +str(acc_value))\n",
    "    correct_pred = tf.equal(tf.argmax(prediction, 1), tf.argmax(Y, 1))\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32))\n",
    "    print(\"Test accuracy: \"+ str(accuracy.eval({X: np.array(temp_x_test), Y: np.array(keras.utils.to_categorical(y_test))})))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part B Change Activation function \n",
    "Activation = **relu** + **tanh** + **tanh**\n",
    "\n",
    "Loss = cross_entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter: 1, Loss: 1.6468\n",
      "Accurancy: 0.21775\n",
      "Iter: 501, Loss: 1.1499\n",
      "Accurancy: 0.42925\n",
      "Iter: 1001, Loss: 1.1925\n",
      "Accurancy: 0.431\n",
      "Iter: 1501, Loss: 1.0932\n",
      "Accurancy: 0.4345\n",
      "Iter: 2001, Loss: 1.0804\n",
      "Accurancy: 0.43475\n",
      "Iter: 2501, Loss: 1.0709\n",
      "Accurancy: 0.4385\n",
      "Iter: 3001, Loss: 1.0665\n",
      "Accurancy: 0.439\n",
      "Iter: 3501, Loss: 1.0661\n",
      "Accurancy: 0.4355\n",
      "Iter: 4001, Loss: 1.0648\n",
      "Accurancy: 0.4355\n",
      "Iter: 4501, Loss: 1.0629\n",
      "Accurancy: 0.4355\n",
      "Iter: 5001, Loss: 1.0615\n",
      "Accurancy: 0.439\n",
      "Iter: 5501, Loss: 1.0617\n",
      "Accurancy: 0.43875\n",
      "Iter: 6001, Loss: 1.0609\n",
      "Accurancy: 0.4385\n",
      "Iter: 6501, Loss: 1.0637\n",
      "Accurancy: 0.43775\n",
      "Iter: 7001, Loss: 1.0615\n",
      "Accurancy: 0.43825\n",
      "Iter: 7501, Loss: 1.0602\n",
      "Accurancy: 0.43875\n",
      "Iter: 8001, Loss: 1.0599\n",
      "Accurancy: 0.4385\n",
      "Iter: 8501, Loss: 1.0596\n",
      "Accurancy: 0.43875\n",
      "Iter: 9001, Loss: 1.0714\n",
      "Accurancy: 0.439\n",
      "Iter: 9501, Loss: 1.0591\n",
      "Accurancy: 0.439\n",
      "Test accuracy: 0.74844337\n"
     ]
    }
   ],
   "source": [
    "EPOCHS = 10000\n",
    "BATCH_SIZE = 1000\n",
    "display_step = 500\n",
    "X = tf.placeholder(\"float\", [None, num_input])\n",
    "Y = tf.placeholder(\"float\", [None, num_classes])\n",
    "\n",
    "# using two numpy arrays\n",
    "features, labels = (X, Y)\n",
    "\n",
    "# make a simple model\n",
    "def Neuron(x):\n",
    "    net = tf.layers.dense(x, 100, activation=tf.nn.relu) # pass the first value \n",
    "    #from iter.get_next() as input\n",
    "    net = tf.layers.dense(net, 50, activation=tf.tanh)\n",
    "    net = tf.layers.dense(net, 20, activation=tf.tanh)\n",
    "    prediction = tf.layers.dense(net, 4)\n",
    "    return prediction\n",
    "\n",
    "\n",
    "prediction = Neuron(X)\n",
    "loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=prediction, labels=Y)) \n",
    "\n",
    "#tf.losses.mean_squared_error(prediction, y) # pass the second value \n",
    "correct_pred = tf.equal(tf.argmax(prediction, 1), tf.argmax(Y, 1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32))\n",
    "\n",
    "#from iter.get_net() as label\n",
    "train_op = tf.train.AdamOptimizer().minimize(loss)\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    sess.run(tf.local_variables_initializer())\n",
    "    for i in range(EPOCHS):\n",
    "        _, loss_value,acc_value = sess.run([train_op, loss,accuracy],feed_dict={X: x, Y: y})\n",
    "        if i% display_step == 0:\n",
    "            print(\"Iter: {}, Loss: {:.4f}\".format(i+1, loss_value)) \n",
    "            print(\"Accurancy: \" +str(acc_value))\n",
    "    correct_pred = tf.equal(tf.argmax(prediction, 1), tf.argmax(Y, 1))\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32))\n",
    "    print(\"Test accuracy: \"+ str(accuracy.eval({X: np.array(temp_x_test), Y: np.array(keras.utils.to_categorical(y_test))})))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Change the activation function. How does it effect the accuracy?\n",
    "\n",
    "**Answer:** The Auccracy gets increased.\n",
    "\n",
    "* How does it effect how quickly the network plateaus?\n",
    "\n",
    "**Answer:**  The plateaus gets shorter."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part C Change Cost function \n",
    "Activation = tanh + relu + softmax\n",
    "\n",
    "Loss = **mean_squared_error**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter: 1, Loss: 0.3317\n",
      "Accurancy: 0.21425\n",
      "Iter: 501, Loss: 0.1688\n",
      "Accurancy: 0.346\n",
      "Iter: 1001, Loss: 0.1579\n",
      "Accurancy: 0.40275\n",
      "Iter: 1501, Loss: 0.1551\n",
      "Accurancy: 0.40425\n",
      "Iter: 2001, Loss: 0.1546\n",
      "Accurancy: 0.399\n",
      "Iter: 2501, Loss: 0.1537\n",
      "Accurancy: 0.4055\n",
      "Iter: 3001, Loss: 0.1533\n",
      "Accurancy: 0.406\n",
      "Iter: 3501, Loss: 0.1531\n",
      "Accurancy: 0.406\n",
      "Iter: 4001, Loss: 0.1533\n",
      "Accurancy: 0.406\n",
      "Iter: 4501, Loss: 0.1530\n",
      "Accurancy: 0.406\n",
      "Iter: 5001, Loss: 0.1528\n",
      "Accurancy: 0.40625\n",
      "Iter: 5501, Loss: 0.1528\n",
      "Accurancy: 0.40625\n",
      "Iter: 6001, Loss: 0.1528\n",
      "Accurancy: 0.40625\n",
      "Iter: 6501, Loss: 0.1528\n",
      "Accurancy: 0.406\n",
      "Iter: 7001, Loss: 0.1528\n",
      "Accurancy: 0.406\n",
      "Iter: 7501, Loss: 0.1528\n",
      "Accurancy: 0.406\n",
      "Iter: 8001, Loss: 0.1528\n",
      "Accurancy: 0.406\n",
      "Iter: 8501, Loss: 0.1528\n",
      "Accurancy: 0.406\n",
      "Iter: 9001, Loss: 0.1528\n",
      "Accurancy: 0.406\n",
      "Iter: 9501, Loss: 0.1529\n",
      "Accurancy: 0.4055\n",
      "Test accuracy: 0.74844337\n"
     ]
    }
   ],
   "source": [
    "EPOCHS = 10000\n",
    "BATCH_SIZE = 1000\n",
    "display_step = 500\n",
    "X = tf.placeholder(\"float\", [None, num_input])\n",
    "Y = tf.placeholder(\"float\", [None, num_classes])\n",
    "\n",
    "# using two numpy arrays\n",
    "features, labels = (X, Y)\n",
    "\n",
    "# make a simple model\n",
    "def Neuron(x):\n",
    "    net = tf.layers.dense(x, 100, activation=tf.tanh) # pass the first value \n",
    "    #from iter.get_next() as input\n",
    "    net = tf.layers.dense(net, 50, activation=tf.nn.relu)\n",
    "    net = tf.layers.dense(net, 20, activation=tf.nn.softmax)\n",
    "    prediction = tf.layers.dense(net, 4)\n",
    "    return prediction\n",
    "\n",
    "\n",
    "prediction = Neuron(X)\n",
    "#loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=prediction, labels=Y)) \n",
    "\n",
    "loss = tf.losses.mean_squared_error(labels=Y, predictions=prediction)\n",
    "\n",
    "#tf.losses.mean_squared_error(prediction, y) # pass the second value \n",
    "correct_pred = tf.equal(tf.argmax(prediction, 1), tf.argmax(Y, 1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32))\n",
    "\n",
    "#from iter.get_net() as label\n",
    "train_op = tf.train.AdamOptimizer().minimize(loss)\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    sess.run(tf.local_variables_initializer())\n",
    "    for i in range(EPOCHS):\n",
    "        _, loss_value,acc_value = sess.run([train_op, loss,accuracy],feed_dict={X: x, Y: y})\n",
    "        if i% display_step == 0:\n",
    "            print(\"Iter: {}, Loss: {:.4f}\".format(i+1, loss_value)) \n",
    "            print(\"Accurancy: \" +str(acc_value))\n",
    "    correct_pred = tf.equal(tf.argmax(prediction, 1), tf.argmax(Y, 1))\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32))\n",
    "    print(\"Test accuracy: \"+ str(accuracy.eval({X: np.array(temp_x_test), Y: np.array(keras.utils.to_categorical(y_test))})))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Change the cost function. How does it effect the accuracy?\n",
    "\n",
    "**Answer:** The Auccracy gets decreased.\n",
    "\n",
    "* How does it effect how quickly the network plateaus?\n",
    "\n",
    "**Answer:**  The plateaus gets longer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part D Change Epochs \n",
    "\n",
    "Activation = tanh + relu + softmax\n",
    "\n",
    "Loss = cross_entropy\n",
    "\n",
    "Epochs = **10000->5000**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter: 1, Loss: 1.3945\n",
      "Accurancy: 0.21725\n",
      "Iter: 501, Loss: 1.2723\n",
      "Accurancy: 0.34925\n",
      "Iter: 1001, Loss: 1.2440\n",
      "Accurancy: 0.3495\n",
      "Iter: 1501, Loss: 1.2311\n",
      "Accurancy: 0.34975\n",
      "Iter: 2001, Loss: 1.2247\n",
      "Accurancy: 0.34975\n",
      "Iter: 2501, Loss: 1.2211\n",
      "Accurancy: 0.34975\n",
      "Iter: 3001, Loss: 1.2188\n",
      "Accurancy: 0.34975\n",
      "Iter: 3501, Loss: 1.1581\n",
      "Accurancy: 0.404\n",
      "Iter: 4001, Loss: 1.1356\n",
      "Accurancy: 0.4045\n",
      "Iter: 4501, Loss: 1.1314\n",
      "Accurancy: 0.40175\n",
      "Test accuracy: 0.6363636\n"
     ]
    }
   ],
   "source": [
    "EPOCHS = 5000\n",
    "BATCH_SIZE = 1000\n",
    "display_step = 500\n",
    "X = tf.placeholder(\"float\", [None, num_input])\n",
    "Y = tf.placeholder(\"float\", [None, num_classes])\n",
    "\n",
    "# using two numpy arrays\n",
    "features, labels = (X, Y)\n",
    "\n",
    "# make a simple model\n",
    "def Neuron(x):\n",
    "    net = tf.layers.dense(x, 100, activation=tf.tanh) # pass the first value \n",
    "    #from iter.get_next() as input\n",
    "    net = tf.layers.dense(net, 50, activation=tf.nn.relu)\n",
    "    net = tf.layers.dense(net, 20, activation=tf.nn.softmax)\n",
    "    prediction = tf.layers.dense(net, 4)\n",
    "    return prediction\n",
    "\n",
    "\n",
    "prediction = Neuron(X)\n",
    "loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=prediction, labels=Y)) \n",
    "\n",
    "#tf.losses.mean_squared_error(prediction, y) # pass the second value \n",
    "correct_pred = tf.equal(tf.argmax(prediction, 1), tf.argmax(Y, 1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32))\n",
    "\n",
    "#from iter.get_net() as label\n",
    "train_op = tf.train.AdamOptimizer().minimize(loss)\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    sess.run(tf.local_variables_initializer())\n",
    "    for i in range(EPOCHS):\n",
    "        _, loss_value,acc_value = sess.run([train_op, loss,accuracy],feed_dict={X: x, Y: y})\n",
    "        if i% display_step == 0:\n",
    "            print(\"Iter: {}, Loss: {:.4f}\".format(i+1, loss_value)) \n",
    "            print(\"Accurancy: \" +str(acc_value))\n",
    "    correct_pred = tf.equal(tf.argmax(prediction, 1), tf.argmax(Y, 1))\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32))\n",
    "    print(\"Test accuracy: \"+ str(accuracy.eval({X: np.array(temp_x_test), Y: np.array(keras.utils.to_categorical(y_test))})))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Change the number of epochs initialization. How does it effect the accuracy?\n",
    "\n",
    "**Answer:** The Auccracy gets decreased.\n",
    "\n",
    "* How does it effect how quickly the network plateaus?\n",
    "\n",
    "**Answer:**  The plateaus gets longer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part E Change Gradient estimation \n",
    "Activation = tanh + relu + softmax\n",
    "\n",
    "Loss = cross_entropy\n",
    "\n",
    "Epochs = 10000\n",
    "\n",
    "optimizer = **ADAM->Adadelta**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter: 1, Loss: 1.3864\n",
      "Accurancy: 0.25725\n",
      "Iter: 501, Loss: 1.3862\n",
      "Accurancy: 0.25725\n",
      "Iter: 1001, Loss: 1.3859\n",
      "Accurancy: 0.25725\n",
      "Iter: 1501, Loss: 1.3856\n",
      "Accurancy: 0.25725\n",
      "Iter: 2001, Loss: 1.3853\n",
      "Accurancy: 0.25725\n",
      "Iter: 2501, Loss: 1.3850\n",
      "Accurancy: 0.25725\n",
      "Iter: 3001, Loss: 1.3847\n",
      "Accurancy: 0.25725\n",
      "Iter: 3501, Loss: 1.3845\n",
      "Accurancy: 0.25725\n",
      "Iter: 4001, Loss: 1.3842\n",
      "Accurancy: 0.25725\n",
      "Iter: 4501, Loss: 1.3839\n",
      "Accurancy: 0.25725\n",
      "Iter: 5001, Loss: 1.3836\n",
      "Accurancy: 0.25725\n",
      "Iter: 5501, Loss: 1.3834\n",
      "Accurancy: 0.25725\n",
      "Iter: 6001, Loss: 1.3831\n",
      "Accurancy: 0.25725\n",
      "Iter: 6501, Loss: 1.3829\n",
      "Accurancy: 0.25725\n",
      "Iter: 7001, Loss: 1.3826\n",
      "Accurancy: 0.25725\n",
      "Iter: 7501, Loss: 1.3824\n",
      "Accurancy: 0.25725\n",
      "Iter: 8001, Loss: 1.3821\n",
      "Accurancy: 0.25725\n",
      "Iter: 8501, Loss: 1.3819\n",
      "Accurancy: 0.253\n",
      "Iter: 9001, Loss: 1.3816\n",
      "Accurancy: 0.25075\n",
      "Iter: 9501, Loss: 1.3814\n",
      "Accurancy: 0.251\n",
      "Test accuracy: 0.24283935\n"
     ]
    }
   ],
   "source": [
    "EPOCHS = 10000\n",
    "BATCH_SIZE = 1000\n",
    "display_step = 500\n",
    "X = tf.placeholder(\"float\", [None, num_input])\n",
    "Y = tf.placeholder(\"float\", [None, num_classes])\n",
    "\n",
    "# using two numpy arrays\n",
    "features, labels = (X, Y)\n",
    "\n",
    "# make a simple model\n",
    "def Neuron(x):\n",
    "    net = tf.layers.dense(x, 100, activation=tf.tanh) # pass the first value \n",
    "    #from iter.get_next() as input\n",
    "    net = tf.layers.dense(net, 50, activation=tf.nn.relu)\n",
    "    net = tf.layers.dense(net, 20, activation=tf.nn.softmax)\n",
    "    prediction = tf.layers.dense(net, 4)\n",
    "    return prediction\n",
    "\n",
    "\n",
    "prediction = Neuron(X)\n",
    "loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=prediction, labels=Y)) \n",
    "\n",
    "#tf.losses.mean_squared_error(prediction, y) # pass the second value \n",
    "correct_pred = tf.equal(tf.argmax(prediction, 1), tf.argmax(Y, 1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32))\n",
    "\n",
    "#from iter.get_net() as label\n",
    "train_op = tf.train.AdadeltaOptimizer().minimize(loss)\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    sess.run(tf.local_variables_initializer())\n",
    "    for i in range(EPOCHS):\n",
    "        _, loss_value,acc_value = sess.run([train_op, loss,accuracy],feed_dict={X: x, Y: y})\n",
    "        if i% display_step == 0:\n",
    "            print(\"Iter: {}, Loss: {:.4f}\".format(i+1, loss_value)) \n",
    "            print(\"Accurancy: \" +str(acc_value))\n",
    "    correct_pred = tf.equal(tf.argmax(prediction, 1), tf.argmax(Y, 1))\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32))\n",
    "    print(\"Test accuracy: \"+ str(accuracy.eval({X: np.array(temp_x_test), Y: np.array(keras.utils.to_categorical(y_test))})))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Change the gradient estimation. How does it effect the accuracy?\n",
    "\n",
    "**Answer:** The Auccracy gets decreased.\n",
    "\n",
    "* How does it effect how quickly the network plateaus?\n",
    "\n",
    "**Answer:**  The plateaus gets longer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part F Change Network Architecture \n",
    "Activation = tanh + relu + softmax\n",
    "\n",
    "Loss = cross_entropy\n",
    "\n",
    "Epochs = 10000\n",
    "\n",
    "optimizer = ADAM\n",
    "\n",
    "**Number of Layers = 3->4**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter: 1, Loss: 1.3879\n",
      "Accurancy: 0.25025\n",
      "Iter: 501, Loss: 1.2725\n",
      "Accurancy: 0.348\n",
      "Iter: 1001, Loss: 1.2429\n",
      "Accurancy: 0.353\n",
      "Iter: 1501, Loss: 1.2302\n",
      "Accurancy: 0.353\n",
      "Iter: 2001, Loss: 1.2237\n",
      "Accurancy: 0.353\n",
      "Iter: 2501, Loss: 1.2199\n",
      "Accurancy: 0.353\n",
      "Iter: 3001, Loss: 1.2175\n",
      "Accurancy: 0.353\n",
      "Iter: 3501, Loss: 1.2159\n",
      "Accurancy: 0.353\n",
      "Iter: 4001, Loss: 1.2163\n",
      "Accurancy: 0.35725\n",
      "Iter: 4501, Loss: 1.1449\n",
      "Accurancy: 0.404\n",
      "Iter: 5001, Loss: 1.1338\n",
      "Accurancy: 0.404\n",
      "Iter: 5501, Loss: 1.1298\n",
      "Accurancy: 0.404\n",
      "Iter: 6001, Loss: 1.1278\n",
      "Accurancy: 0.404\n",
      "Iter: 6501, Loss: 1.1225\n",
      "Accurancy: 0.404\n",
      "Iter: 7001, Loss: 1.1211\n",
      "Accurancy: 0.4045\n",
      "Iter: 7501, Loss: 1.1203\n",
      "Accurancy: 0.40525\n",
      "Iter: 8001, Loss: 1.1221\n",
      "Accurancy: 0.403\n",
      "Iter: 8501, Loss: 1.1206\n",
      "Accurancy: 0.40325\n",
      "Iter: 9001, Loss: 1.1202\n",
      "Accurancy: 0.404\n",
      "Iter: 9501, Loss: 1.1206\n",
      "Accurancy: 0.4035\n",
      "Test accuracy: 0.6351183\n"
     ]
    }
   ],
   "source": [
    "EPOCHS = 10000\n",
    "BATCH_SIZE = 1000\n",
    "display_step = 500\n",
    "X = tf.placeholder(\"float\", [None, num_input])\n",
    "Y = tf.placeholder(\"float\", [None, num_classes])\n",
    "\n",
    "# using two numpy arrays\n",
    "features, labels = (X, Y)\n",
    "\n",
    "# make a simple model\n",
    "def Neuron(x):\n",
    "    net = tf.layers.dense(x, 100, activation=tf.tanh) # pass the first value \n",
    "    #from iter.get_next() as input\n",
    "    net = tf.layers.dense(net, 50, activation=tf.nn.relu)\n",
    "    net = tf.layers.dense(net, 30, activation=tf.nn.relu)\n",
    "    net = tf.layers.dense(net, 20, activation=tf.nn.softmax)\n",
    "    prediction = tf.layers.dense(net, 4)\n",
    "    return prediction\n",
    "\n",
    "\n",
    "prediction = Neuron(X)\n",
    "loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=prediction, labels=Y)) \n",
    "\n",
    "#tf.losses.mean_squared_error(prediction, y) # pass the second value \n",
    "correct_pred = tf.equal(tf.argmax(prediction, 1), tf.argmax(Y, 1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32))\n",
    "\n",
    "#from iter.get_net() as label\n",
    "train_op = tf.train.AdamOptimizer().minimize(loss)\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    sess.run(tf.local_variables_initializer())\n",
    "    for i in range(EPOCHS):\n",
    "        _, loss_value,acc_value = sess.run([train_op, loss,accuracy],feed_dict={X: x, Y: y})\n",
    "        if i% display_step == 0:\n",
    "            print(\"Iter: {}, Loss: {:.4f}\".format(i+1, loss_value)) \n",
    "            print(\"Accurancy: \" +str(acc_value))\n",
    "    correct_pred = tf.equal(tf.argmax(prediction, 1), tf.argmax(Y, 1))\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32))\n",
    "    print(\"Test accuracy: \"+ str(accuracy.eval({X: np.array(temp_x_test), Y: np.array(keras.utils.to_categorical(y_test))})))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Change the network architecture. How does it effect the accuracy?\n",
    "\n",
    "**Answer:** The Auccracy gets slightly increased.\n",
    "\n",
    "* How does it effect how quickly the network plateaus?\n",
    "\n",
    "**Answer:**  The plateaus gets shorter."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part G Change Network initialization  \n",
    "Activation = tanh + relu + softmax\n",
    "\n",
    "Loss = cross_entropy\n",
    "\n",
    "Epochs = 10000\n",
    "\n",
    "optimizer = ADAM\n",
    "\n",
    "Initializer = **Zero->Xavier Uniform**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter: 1, Loss: 1.3981\n",
      "Accurancy: 0.24975\n",
      "Iter: 501, Loss: 1.2789\n",
      "Accurancy: 0.345\n",
      "Iter: 1001, Loss: 1.2441\n",
      "Accurancy: 0.3525\n",
      "Iter: 1501, Loss: 1.2311\n",
      "Accurancy: 0.3525\n",
      "Iter: 2001, Loss: 1.2246\n",
      "Accurancy: 0.349\n",
      "Iter: 2501, Loss: 1.2209\n",
      "Accurancy: 0.3525\n",
      "Iter: 3001, Loss: 1.2186\n",
      "Accurancy: 0.3525\n",
      "Iter: 3501, Loss: 1.2171\n",
      "Accurancy: 0.3525\n",
      "Iter: 4001, Loss: 1.2160\n",
      "Accurancy: 0.3525\n",
      "Iter: 4501, Loss: 1.1488\n",
      "Accurancy: 0.40375\n",
      "Iter: 5001, Loss: 1.1304\n",
      "Accurancy: 0.40375\n",
      "Iter: 5501, Loss: 1.1256\n",
      "Accurancy: 0.40375\n",
      "Iter: 6001, Loss: 1.1237\n",
      "Accurancy: 0.40475\n",
      "Iter: 6501, Loss: 1.1222\n",
      "Accurancy: 0.40475\n",
      "Iter: 7001, Loss: 1.1213\n",
      "Accurancy: 0.40475\n",
      "Iter: 7501, Loss: 1.1205\n",
      "Accurancy: 0.40475\n",
      "Iter: 8001, Loss: 1.1194\n",
      "Accurancy: 0.40475\n",
      "Iter: 8501, Loss: 1.1183\n",
      "Accurancy: 0.40475\n",
      "Iter: 9001, Loss: 1.1175\n",
      "Accurancy: 0.40475\n",
      "Iter: 9501, Loss: 1.1165\n",
      "Accurancy: 0.40575\n",
      "Test accuracy: 0.6351183\n"
     ]
    }
   ],
   "source": [
    "EPOCHS = 10000\n",
    "BATCH_SIZE = 1000\n",
    "display_step = 500\n",
    "X = tf.placeholder(\"float\", [None, num_input])\n",
    "Y = tf.placeholder(\"float\", [None, num_classes])\n",
    "\n",
    "# using two numpy arrays\n",
    "features, labels = (X, Y)\n",
    "\n",
    "# make a simple model\n",
    "def Neuron(x):\n",
    "    net = tf.layers.dense(x, 100, activation=tf.tanh, bias_initializer=tf.glorot_uniform_initializer()) # pass the first value \n",
    "    #from iter.get_next() as input\n",
    "    net = tf.layers.dense(net, 50, activation=tf.nn.relu, bias_initializer=tf.glorot_uniform_initializer())\n",
    "    net = tf.layers.dense(net, 20, activation=tf.nn.softmax, bias_initializer=tf.glorot_uniform_initializer())\n",
    "    prediction = tf.layers.dense(net, 4)\n",
    "    return prediction\n",
    "\n",
    "\n",
    "prediction = Neuron(X)\n",
    "loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=prediction, labels=Y)) \n",
    "\n",
    "#tf.losses.mean_squared_error(prediction, y) # pass the second value \n",
    "correct_pred = tf.equal(tf.argmax(prediction, 1), tf.argmax(Y, 1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32))\n",
    "\n",
    "#from iter.get_net() as label\n",
    "train_op = tf.train.AdamOptimizer().minimize(loss)\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    sess.run(tf.local_variables_initializer())\n",
    "    for i in range(EPOCHS):\n",
    "        _, loss_value,acc_value = sess.run([train_op, loss,accuracy],feed_dict={X: x, Y: y})\n",
    "        if i% display_step == 0:\n",
    "            print(\"Iter: {}, Loss: {:.4f}\".format(i+1, loss_value)) \n",
    "            print(\"Accurancy: \" +str(acc_value))\n",
    "    correct_pred = tf.equal(tf.argmax(prediction, 1), tf.argmax(Y, 1))\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32))\n",
    "    print(\"Test accuracy: \"+ str(accuracy.eval({X: np.array(temp_x_test), Y: np.array(keras.utils.to_categorical(y_test))})))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Change the network initialization. How does it effect the accuracy?\n",
    "\n",
    "**Answer:** The Auccracy gets decreased.\n",
    "\n",
    "* How does it effect how quickly the network plateaus?\n",
    "\n",
    "**Answer:**  The plateaus gets longer."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
